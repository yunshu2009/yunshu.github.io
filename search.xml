<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker 学习实践]]></title>
    <url>%2F2018%2F08%2F22%2Fdocker-%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[docker 介绍docker 是一个开源的应用容器引擎，使用 docker 可以轻松地创建一个可移植的、自给自足的容器。开发者在本地编译测试通过的容器可以直接在服务器生成环境上部署。 在 docker 中，一个容器对应着一个服务。比如我们的系统有web容器，mysql容器、redis容器。每一个容器的数据和配置文件都是在宿主主机上面，通过 volumes 挂载到容器的相应文件夹中（我们在 ./docker-compose.yml 配置文件中的 volumes 做了宿主主机文件和容器主机文件的映射） docker参考文档英文文档https://docs.docker.com/ 中文文档https://docs.docker-cn.com/ http://www.docker.org.cn/page/resources.html 其它文档初识 docker 搭建自己的开发环境 https://laravel-china.org/articles/10170/the-first-docker-to-build-their-own-development-environment 自建 Laravel 的 Docker 开发环境 https://laravel-china.org/articles/14767/self-built-laravel-docker-development-environment docker 命令1234567891011121314151617181920212223#启动docker服务service docker start#构建镜像chmod 755 /usr/local/bin/docker-composedocker-compose build##运行docker容器docker-compose updocker-compose up -d（后台运行）##查看compose启动的各个容器的状态docker-compose ps##进入某个容器,譬如phpdocker-compose exec php bash#退出某个容器exit#停止 docker 容器docker-compose stop OK. 后续不断完善~]]></content>
  </entry>
  <entry>
    <title><![CDATA[php 代码自动部署方案]]></title>
    <url>%2F2018%2F08%2F22%2Fphp-%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[方案一 使用 gitlab ci 自动部署参考链接：https://blog.csdn.net/hxpjava1/article/details/78514999 附：一份示例配置 1234567891011121314stages: - deploydeploy: stage: deploy script: - sudo cp -a . /data/wwwroot/my-project - cd /data/wwwroot/my-project - sudo composer install - sudo cp .env.example .env - sudo chmod 777 -R /data/wwwroot/my-project/runtime only: - dev tags: - yunshudev 方案二 使用 deloyer 部署参考链接： https://laravel-china.org/articles/13242/another-introduction-to-the-use-of-deployer]]></content>
  </entry>
  <entry>
    <title><![CDATA[Nginx 相关总结]]></title>
    <url>%2F2018%2F08%2F20%2FNginx-%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Nginx 基础Nginx 日志log_format指令用来设置日志的记录格式，它的语法如下：log_format name format {format …}其中name表示定义的格式名称，format表示定义的格式样式。 在 format 定义中可以添加 X-Forwarded-For 信息, 用来记录客户的真实 IP。更多信息可参考：https://www.cnblogs.com/kevingrace/p/5893499.html。 例如：nginx 的 负载均衡代理层使用过的一个配置添加一条 log_format： 123log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;$http_user_agent $http_x_forwarded_for $request_time $upstream_response_time $upstream_addr $upstream_status&apos;; 然后指定 access_log 的级别为main，即可 1access_log logs/www-yunshu-me_access.log main; 场景应用静态资源web服务一些优化配置：123456sendfile on|offtcp_nopush on|off #一次性发送多个文件，而不是每次都发送 （需要和 sendfile 配合使用。对于大文件推荐使用。）tcp_nodelay on|off #实时发送文件 （与 tcp_nopush 配置相对。需要在keepalive开启的情况下使用）gzip on #对传输的资源压缩，减少使用的带宽，提高传输的实时性gzip_comp_level level #资源压缩比gzip_static on|off #预读文件。使用压缩功能，需要安装 nginx 时编译 http_gzip_static_module 模块。http_gzip_static_module 会先去磁盘找有没对应的 gzip 文件，如果有就返回给客户端，减少了动态压缩资源的消耗。 浏览器缓存 浏览器缓存校验机制 校验是否过期：Expires、Cache-Control(max-age) Expires是 http 1.0 定义的，Cache-Controll 是 http1.1 里定义的。 服务器端 Etag 头信息校验：Etag 服务器端 Last-Modified 校验：Last-Modified 配置 1expires time #为响应头添加 Last-Modified 头信息 跨域访问允许跨站访问的 nginx 配置 123add_header Access-Control-Allow-Origin *; //可以指定特定域名add_header Access-Control-Allow-Headers X-Requested-With; //设置允许的头信息add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE,OPTIONS; 防盗链基于 http_refer 防盗链配置： 123456location ~ .*\.(wma|wmv|asf|mp3|mmf|zip|rar|jpg|gif|png|swf|flv|mp4)$ &#123; valid_referers none blocked *.yunshu.me; //valid_referers 表示允许那些情况可以访问，none 表示不带referer头的情况，blocked 表示没有携带协议信息的情况，“*.yunshu.me”表示所有 yunshu.me 二级域名都可访问 if ($invalid_referer) &#123; rewrite ^/ http://www.yunshu.me; return 403; &#125; 防盗链测试： 1234//“-I” 表示只返回 http 头信息，“-e”用于指定 referer 头curl -e http://www.abc.com -I http://yunshu.me/3/s26676928.jpg//不带 referer 头curl -I http://yunshu.me/3/s26676928.jpg 代理服务正向代理： 场景：使用代理服务器翻墙。 反向代理： 场景：使用反向代理实现负载均衡 正向代理和反向代理的区别： 代理的对象不一样，正向代理代理的是客户端，为了客户端能访问目标网站。反向代理的对象是服务端，代理设置是在服务端的，为了服务端能返回客户端所需数据。 配置实例： 反向代理： 12345//当服务器接受到请求后，将请求发送到 8080 端口。 location / &#123; proxy_pass http://127.0.0.1:8080; &#125; 正向代理: 123456789server&#123; resolver 8.8.8.8; listen 82; location / &#123; proxy_pass http://$http_host$request_uri; &#125;&#125; nginx 实现正向代理上网，有三个关键点必须注意，其余的配置跟普通的nginx一样 1.增加dns解析resolver 2.增加无 server_name 名的 server 3.proxy_pass指令 正向代理测试： curl设置代理访问: curl -x ip:82 test.comwget设置代理访问 wget -Y on -e “http_proxy=http://ip:82“ “test.com” 代理配置更多配置参考：http://nginx.org/en/docs/http/ngx_http_proxy_module.html 负载均衡服务缓存服务Nginx 深入学习篇Nginx 架构篇]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说一下消息队列与 Gearman 任务队列]]></title>
    <url>%2F2018%2F08%2F20%2F%E8%AF%B4%E4%B8%80%E4%B8%8B%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%8E-Gearman-%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[之前写的关于 Gearman 的PPT: http://s2.yunshudm.com/gearman.pdf]]></content>
  </entry>
  <entry>
    <title><![CDATA[再说 PHP 安全与 ThinkPHP 安全防范措施]]></title>
    <url>%2F2018%2F08%2F20%2F%E5%86%8D%E8%AF%B4-PHP-%E5%AE%89%E5%85%A8%E4%B8%8E-ThinkPHP-%E5%AE%89%E5%85%A8%E9%98%B2%E8%8C%83%E6%8E%AA%E6%96%BD%2F</url>
    <content type="text"><![CDATA[php 应用安全include 安全如果要求用户输入文件，然后在 php 里对文件进行包含，就要注意include 安全防范。 防范措施： 使用basename() 返回路径中的文件名部分 使用realpath()，将相对路径转换为绝对路径 开放全局注册配置项 Register_globals 在PHP 5.3.0 起废弃并将自 PHP 5.4.0 起移除。 用户如果配置了 Register_globals=ON， 用户可以通过提交的 GET 参数来覆盖变量。 示例： 12345$b = &apos;b&apos;;var_export($_GET);parse_str($a[$_GET[&apos;var&apos;]]);print $b; 解决方法：Register_globals=OFF （默认为OFF） MD5 密码加盐XSSXSS攻击全称跨站脚本攻击，（英语：Cross-site scripting，通常简称为：XSS）是一种网站应用程序的安全漏洞攻击，是代码注入的一种。它允许恶意用户将代码注入到网页上，其他用户在观看网页时就会受到影响。这类攻击通常包含了HTML以及用户端脚本语言。 防范措施： 使用 htmlpurifier 对输出进行过滤。它会对 html 检查，只运行在白名单上的标签和属性通过，其它都过滤。 链接： http://htmlpurifier.org/ https://github.com/mewebstudio/Purifier 禁止 js 脚本读取cookie，只允许通过 http 传输。 在 php 里设置：session.cookie_httponly = On 通过函数过滤 1.通过strip_tags()过滤标签 2.转换引号 htmlentities($str, ENT_QUOTES); 3.要把unicode编码前面的\给转成实体, 使unicode编码就没法解析 str_replace(‘\’,‘&#x005C;’) 4.转换script标签、expression标签等 PHP 漏洞检测扩展 taint ，可用于检测 XSS , SQL 注入， shell 注入等，可以在开发时使用。链接：http://pecl.php.net/package/taint sql 注入通过把 sql 命令插入到 Web 通过表单提交或通过请求的查询字符串，进行通过代码执行恶意的 sql 语句。 sql注入示例： 查询mysql版本: SELECT title,content FROM article WHERE id=‘-1’ union select version(),2 – ’ 查询当前连接的数据库 SELECT title,content FROM article WHERE id=‘-1’ union select database(),2 – ’ 查询数据库结构: SELECT title,content FROM article WHERE id=‘-1’ union1, select (SELECT (@) FROM (SELECT(@:=0x00),(SELECT (@) FROM (information_schema.columns) WHERE (table_schema&gt;=@) AND (@)IN (@:=CONCAT(@,0x0a,‘ [ ’,table_schema,‘ ] &gt;’,table_name,‘ &gt; ’,column_name))))x) –’ 查询用户名密码 SELECT title,content FROM article WHERE id=‘-1’ union select username,password from user– 万能登录密码 SELECT * FROM user WHERE username=‘admin’ – ’ AND password=‘xxxx’ 查看文件:SELECT title,content FROM article WHERE id=‘-1’ union select 1,load_file(‘/etc/passwd’) – ’ 防范措施： 通过字段过滤 如：intval()、filter_var() 数字加引号 对拼接 sql 的参数使用 mysql_real_escape_string() 对参数进行转义 使用PDO参数绑定（对于 thinkphp 框架尽量使用框架数组传参而不是拼接） 尽量降低应用数据库账户的数据库操作权限 CSRF 攻击CSRF（Cross-site request forgery）跨站请求伪造，也被称为“One Click Attack”或者Session Riding，通常缩写为CSRF或者XSRF。CSRF 攻击通过伪装来自受信任用户的请求来利用受信任的网站。攻击示例：微博刷粉丝。 防范措施： 判断来源 $_SERVER[‘HTTP_REFERER’] 令牌验证。表单隐藏域随机字符串作为令牌，存储在 session 中，应用提交比对 session 中的令牌和提交的令牌是否一致。 上传漏洞文件上传漏洞是指网络攻击者上传了一个可执行的文件到服务器并执行。这里上传的文件可以是木马，病毒，恶意脚本或者WebShell等。 防范措施： 上传文件类型检查。 上传文件和程序文件分离。(将上传文件放置在单独的目录,文件设置为可读。设置访问目录时不能执行 php 脚本) thinkphp 5对上传的安全防范thinkphp 5 对上传文件的验证，包括对文件大小、文件类型和后缀的验证。 源码参考：https://github.com/top-think/framework/blob/5.1/library/think/File.php 其它一些输入/输出过滤函数str_replace、htmlspecialchars、nl2br、escapeshellcmd、escapeshellarg 配置项配置 safe_mode_exec_dir ,让php只能执行指定目录下的命令程序 更多参考HTML 转义字符表 http://tool.oschina.net/commons?type=2PHP Filter 函数 http://www.w3school.com.cn/php/php_ref_filter.asp跨站点脚本攻击深入解析 https://www.ibm.com/developerworks/cn/rational/08/0325_segal/PHP代码审计分段讲解 https://github.com/bowu678/php_bugs]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用 Laravel 与 Elasticsearch 实现文章全文检索功能]]></title>
    <url>%2F2018%2F08%2F19%2F%E4%BD%BF%E7%94%A8-Laravel-%E4%B8%8E-Elasticsearch-%E5%AE%9E%E7%8E%B0%E6%96%87%E7%AB%A0%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[搭建 Composer 私有源并发布自己的 Composer 包]]></title>
    <url>%2F2018%2F08%2F19%2F%E6%90%AD%E5%BB%BA-composer-%E7%A7%81%E6%9C%89%E6%BA%90%E5%B9%B6%E5%8F%91%E5%B8%83%E8%87%AA%E5%B7%B1%E7%9A%84-composer-%E5%8C%85%2F</url>
    <content type="text"><![CDATA[参考链接： Composer 文档 英文版https://getcomposer.org/doc/articles/handling-private-packages-with-satis.md 中文版https://laravel-china.org/docs/composer/2018/handling-private-packages-with-satis/2092 PHP PSR代码规范 英文版 https://www.php-fig.org/psr/ 中文版 https://laravel-china.org/docs/psr PHP 包仓库 https://packagist.org/ 其它 使用 satis 搭建一个私有的 Composer 包仓库https://laravel-china.org/topics/1900/use-satis-to-build-a-private-composer-warehouse PHP创建自己的Composer包方法https://www.jb51.net/article/137923.htm]]></content>
  </entry>
  <entry>
    <title><![CDATA[搭建 Git 服务器]]></title>
    <url>%2F2018%2F08%2F19%2F%E6%90%AD%E5%BB%BA-Git-%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[不知道为啥，使用 hexo 渲染本篇文章时，格式总是乱掉，所以将这篇文章放到简书了。 传送门：https://www.jianshu.com/p/786d93c56801]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 django 开发一个微信文章阅览网站]]></title>
    <url>%2F2018%2F08%2F18%2F%E4%BD%BF%E7%94%A8-django-%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%BE%AE%E4%BF%A1%E6%96%87%E7%AB%A0%E9%98%85%E8%A7%88%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[千万级秒级php电商秒杀项目实战学习总结]]></title>
    <url>%2F2018%2F08%2F18%2F%E5%8D%83%E4%B8%87%E7%BA%A7%E7%A7%92%E7%BA%A7php%E7%94%B5%E5%95%86%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[利用 Swoole 实现 PHP+websocket 聊天室]]></title>
    <url>%2F2018%2F08%2F18%2F%E5%88%A9%E7%94%A8Swoole%E5%AE%9E%E7%8E%B0PHP-websocket-%E8%81%8A%E5%A4%A9%E5%AE%A4%2F</url>
    <content type="text"><![CDATA[关于 SwoolePHP语言的异步、并行、高性能网络通信框架，使用纯C语言编写，提供了PHP语言的异步多线程服务器，异步TCP/UDP网络客户端，异步MySQL，数据库连接池，AsyncTask，消息队列，毫秒定时器，异步文件读写，异步DNS查询。 支持的服务： HttpServer WebSocket Server TCP Server TCP Client Async-IO(异步) Task(定时任务) 官方文档：https://www.swoole.com/ 安装swoole123pecl install swooleecho &quot;extension=swoole.so&quot; &gt; /usr/local/php/etc/php.d/ext-swoole.iniservice php-fpm restart 开发一个简单的聊天室服务端 代码1234567891011121314151617181920&lt;?php//创建websocket服务器对象，监听0.0.0.0:9502端口$server = new swoole_websocket_server(&quot;0.0.0.0&quot;, 9502);//监听WebSocket连接打开事件$server-&gt;on(&apos;open&apos;, function (swoole_websocket_server $server, $request) &#123; echo &quot;server: handshake success with fd&#123;$request-&gt;fd&#125;\n&quot;; $GLOBALS[&apos;fd&apos;][] = $request-&gt;fd;&#125;);//监听WebSocket消息事件$server-&gt;on(&apos;message&apos;, function (swoole_websocket_server $server, $frame) &#123; $msg = &quot;receive from &#123;$frame-&gt;fd&#125;:&#123;$frame-&gt;data&#125;,opcode:&#123;$frame-&gt;opcode&#125;,fin:&#123;$frame-&gt;finish&#125;,fd:&#123;$frame-&gt;fd&#125;\n&quot;; echo $msg; foreach($GLOBALS[&apos;fd&apos;] as $fd)&#123; $server-&gt;push($fd, $msg); &#125;&#125;); 客户端 代码参考：https://github.com/yunshu2009/swoole-src/blob/master/examples/websocket/client.html 学习资料 easyswoole:https://github.com/easy-swoole/easyswoole 《Linux高性能服务器编程》]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>Swoole</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式总结]]></title>
    <url>%2F2018%2F08%2F17%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[面向对象的六大原则 单一职责原则:避免职责分散,避免承担太多(SRP) 开闭原则:模块应对扩展开放,而对修改关闭(OCP) 里氏代换原则:子类必须能替换掉父类(LSP) 依赖倒转原则:父类不依赖子类,抽象不依赖具体(DIP) 接口隔离原则:职业单一,承诺最简(ISP) 组合复用原则:尽量使用组合,避免滥用继承(CRP) 设计模式是什么 一套被反复使用、多人知晓、经分类编目的代码设计经验的总结 设计模式正是对面向对象原则的深入研究和应用 并不是说所有的设计模式都得在面向对象时使用, 在面向过程中也可以使用。 不要生帮硬套设计模式, 在重构代码时可以考虑设计模式让代码更方便修改和复用 设计模式并不高深, 很可能用到了很多模式只是没有提炼出来 设计模式的类型根据《设计模式 - 可复用的面向对象软件元素》一书中所提到的，总共有 23 种设计模式。这些模式可以分为三大类：创建型模式（Creational Patterns）、结构型模式（Structural Patterns）、行为型模式（Behavioral Patterns） 序号 模式 &amp; 描述 包括 1 创建型模式 工厂模式（Factory Pattern）抽象工厂模式（Abstract Factory Pattern）单例模式（Singleton Pattern）建造者模式（Builder Pattern）原型模式（Prototype Pattern） 2 结构型模式 适配器模式（Adapter Pattern）桥接模式（Bridge Pattern）过滤器模式（Filter、Criteria Pattern）组合模式（Composite Pattern）装饰器模式（Decorator Pattern）外观模式（Facade Pattern）享元模式（Flyweight Pattern）代理模式（Proxy Pattern） 3 行为型模式 责任链模式（Chain of Responsibility Pattern）命令模式（Command Pattern）解释器模式（Interpreter Pattern）迭代器模式（Iterator Pattern）中介者模式（Mediator Pattern）备忘录模式（Memento Pattern）观察者模式（Observer Pattern）状态模式（State Pattern）空对象模式（Null Object Pattern）策略模式（Strategy Pattern）模板模式（Template Pattern）访问者模式（Visitor Pattern） 模式简介/php 代码实现单例模式在整个程序的生命周期只允许出现一个实例 迭代器模式提供一种方法顺序的访问一个聚合对象中各个元素，而又不暴露该对象的内部表示（有多少个元素，每个元素是怎么样的） 工厂模式简单工厂模式简单工厂模式：提供一个公共的接口来创建类的实例。 解决的问题：将“类实例化操作”和“使用对象的操作”分开，让使用者不用知道具体参数就可以实例化是需要的“产品”类，从而避免了在客户端代码中显式指定，实现了解耦。 优点： 使得客户端不必关心如何创建类的实例，屏蔽了一些类实例创建的复杂性 缺点： 工厂类集中了所有相关类实例的创建逻辑，一旦这个工厂不能正常工作，整个系统都会受到影响； 违背“开放 - 关闭原则”，一旦添加新产品就不得不修改工厂类的逻辑，这样就会造成工厂逻辑过于复杂。 当需要大量相关类实例的创建工作时，工厂类会比较庞大，创建逻辑会比较复杂。 使用场景： 客户端只想传入创建实例的参数，不关心如何创建类实例。 当创建类的实例较少时 工厂方法模式工厂方法模式：定义工厂父类负责创建类的公共接口，而子类则负责生成具体的对象。 工厂方法模式使得添加类实例创建时不必修改工厂类逻辑而是添加新的工厂子类，符合开放封闭原则（开放封闭原则：设计好类后就不再修改，如果有新的需求，通过新加类的方式来满足，而不去修改现有的类（代码））。 解决的问题：克服简单工厂模式的不足，即添加类实例创建逻辑时需要修改公共的工厂类。 优点： 只需要知道对应的工厂名，就可以创建对应的实例。 创建类实例时只需要添加对应的工厂类即可。 缺点： 由于创建类时，需要有对应的工厂类，所以系统类的数量会比较多，增加系统的复杂性。 使用场景： 不知道需要创建的类名，只知道某个子类工厂的类名时，可使用工厂方法创建新的实例。 抽象工厂模式抽象工厂模式：有多个工厂生产产品，每个工厂又有多条产品线生产产品。在抽象工厂模式中，每一个工厂可以创建多个类的实例。适合有很多个类需要创建，多个类实体又可以抽象成一个整体的时候使用。 中介者模式使用中介类来处理其它类（多个类）的业务逻辑，属于行为型模式。 适配器模式适配器模式：需要转化一个对象的接口用于另一个对象。使用适配器模式，多个不同的类实现相同的接口。 模板模式模板模式：一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。 装饰器模式装饰器模式：允许向一个现有的对象添加新的功能,同时又不改变其结构装饰模式把子类中比基类中多出来的部分放到单独的类里面，以适应新功能增加的需要。 建造者模式建造者模式：将创建一个对象的复杂过程封装起来，使对象的创建过程与它的表示分离 原型模式原型模式：用较低成本方式创建高成本的实例。属于创建型模式这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，可以采用这种模式。 组合模式组合模式：用引用方式而不是继承来构造一个复杂的对象。 相比继承模式，当继承层次多了，子类会继承一些用不到的属性，存在浪费的现象，组合模式就不存在这种情况。组合模式是结构型模式。 外观模式外观模式：通过向客户端提供一个可以访问的系统的接口来统一处理多个关联对象的逻辑，隐藏系统的复杂性。外观模式属于结构型模式。 代码：https://github.com/yunshu2009/php-design-patterns]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mycat 数据库中间件使用]]></title>
    <url>%2F2018%2F08%2F17%2Fmycat-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E9%97%B4%E4%BB%B6%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP7新特性]]></title>
    <url>%2F2018%2F08%2F17%2FPHP7%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[目前 PHP 的最新版本是 7.2.9 ，从 PHP 5.6 到 PHP 7 发生了许多变化。在Mac系统下可用php-version工具来切换php版本。 参考资料： http://php.net/manual/zh/appendices.php https://mengkang.net/1019.html 一些PHP 7.0 新特性/变更7.0 新特性 null合并运算符 变量类型声明 变量类型声明可以有两种模式：强制（默认）和严格模式。类型参数可以定义为：字符串（string）、整形（int）、浮点型（float）以及布尔值（bool）。 123456789101112131415161718function sumOfInts(int ...$ints)&#123; return array_sum($ints);&#125;var_dump(sumOfInts(2, &apos;3&apos;, 4.1)); // int(9)// 开启类型声明严格模式，declare 语句需要放在脚本第一行declare(strict_types=1); function add(int $x, int $y)&#123; return $x + $y;&#125;var_dump(add(2, 3)); //Fatal error: Argument 1 passed to add() must be of the type integer 返回值类型声明 组合比较符（添加’&lt;=&gt;’运算符） 组合比较符用于比较两个表达式。当$a小于、等于或大于$b时它分别返回-1、0或1。 12345&lt;?php// 整数echo 1 &lt;=&gt; 1; // 0echo 1 &lt;=&gt; 2; // -1echo 2 &lt;=&gt; 1; // 1 通过define()定义常量数组 支持通过new class来实例化一个匿名类 1234567891011121314151617181920212223242526&lt;?phpinterface Logger &#123; public function log(string $msg);&#125;class Application &#123; private $logger; public function getLogger(): Logger &#123; return $this-&gt;logger; &#125; public function setLogger(Logger $logger) &#123; $this-&gt;logger = $logger; &#125;&#125;$app = new Application;$app-&gt;setLogger(new class implements Logger &#123; public function log(string $msg) &#123; echo $msg; &#125;&#125;);var_dump($app-&gt;getLogger());?&gt; Closure::call()新式闭包绑定 1234567891011&lt;?phpclass A &#123;private $x = 1;&#125;// PHP 7 之前版本的代码$getXCB = function() &#123;return $this-&gt;x;&#125;;$getX = $getXCB-&gt;bindTo(new A, &apos;A&apos;); // 中间层闭包echo $getX();// PHP 7+ 及更高版本的代码$getX = function() &#123;return $this-&gt;x;&#125;;echo $getX-&gt;call(new A); 预期 提供当断言失败时抛出特定异常的能力 1234567&lt;?phpini_set(&apos;assert.exception&apos;, 1);class CustomError extends AssertionError &#123;&#125;assert(false, new CustomError(&apos;Some error message&apos;)); //结果为Fatal error: Uncaught CustomError: Some error message ?&gt; 新添整数除法函数 intdiv() 1var_dump(intdiv(10, 3)); // int(3) 会话选项 session_start() 可以接受一个 array 作为参数， 用来覆盖 php.ini 文件中设置的 会话配置选项。 不向后兼容的变更错误和异常处理相关的变更在 PHP 7 中，很多致命错误以及可恢复的致命错误，都被转换为异常来处理了。 这些异常继承自 Error 类，此类实现了 Throwable 接口 （所有异常都实现了这个基础接口） Throwable层次结构 123456789interface Throwable |- Exception implements Throwable |- ... |- Error implements Throwable |- TypeError extends Error |- ParseError extends Error |- AssertionError extends Error |- ArithmeticError extends Error |- DivisionByZeroError extends ArithmeticError 为了兼容 PHP 5 和 PHP 7, 应该修改set_exception_handler()， 不应该指定参数类型为Exception，因为传递进来的参数类型可能为Error。 12345678910// PHP 5 时代的代码将会出现问题function handler(Exception $e) &#123; &#125;set_exception_handler(&apos;handler&apos;);// 兼容 PHP 5 和 7function handler($e) &#123; &#125;// 仅支持 PHP 7function handler(Throwable $e) &#123; &#125; 被移除的函数 所有的ereg*函数 mcrypt 别名已废弃的 mcrypt_generic_end() 函数已被移除，请使用mcrypt_generic_deinit()代替。 此外，已废弃的 mcrypt_ecb(), mcrypt_cbc(), mcrypt_cfb() 和 mcrypt_ofb() 函数已被移除，请配合恰当的MCRYPTMODE* 常量来使用 mcrypt_decrypt()进行代替 所有 ext/mysql 函数 其它变更 $HTTP_RAW_POST_DATA 被移除 $HTTP_RAW_POST_DATA 被移除，使用php://input代替 new 操作符创建的对象不能以引用方式赋值给变量 12345&lt;?phpclass C &#123;&#125;$c =&amp; new C;?&gt; 在 PHP 7 中将发生语法错误 在 PHP 7 中使用 PHP4 风格的构造函数，PHP7 会产生 E_DEPRECATED 警告。 如果还定义了 __construct() 方法则不受影响。 一些 7.1 新特性/变更新特性 添加返回值类型void 短数组语法[] 短数组语法（[]）现在作为list()语法的一个备选项，可以用于将数组的值赋给一些变量（包括在foreach中） 1234567891011121314151617181920$data = [ [1, &apos;Tom&apos;], [2, &apos;Fred&apos;],];// list() stylelist($id1, $name1) = $data[0];// [] style[$id1, $name1] = $data[0];// list() styleforeach ($data as list($id, $name)) &#123; // logic here with $id and $name&#125;// [] styleforeach ($data as [$id, $name]) &#123; // logic here with $id and $name&#125; 可设置类常量可见性 多异常捕获处理 list()现在支持键名 支持为负的字符串偏移量 不向后兼容的变更 当传递参数过少时将抛出错误 在之前传递参数过少时将抛出警告（warning），现在将抛出异常（Error execption）。 废弃的特性 移除ext/mcrypt 此扩展被 OpenSSL 所取代。]]></content>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记]]></title>
    <url>%2F2018%2F08%2F17%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[什么是 Redis？Redis是一个开源的使用 ANSI C 语言编写、遵守BSD协议、基于内存并可持久化的 K-V 非关系型数据库。 Redis 和 Memcache的区别 Redis 数据类型丰富。Redis不仅仅支持简单的数据类型，还支持list、set、sortedset、hash等数据结构。 Redis可利用虚拟内存。Redis 当物理内存用完时，可以将一些很久没用到的 value 交换到磁盘。 Redis 支持数据持久化。当 Memcache 挂掉后，数据就没了。而 Redis 可以定期将数据保存到磁盘。 Redis 支持灾难恢复。当Memcache挂掉后，数据不可恢复; 而 Redis 数据丢失后可以通过AOF 恢复。 Redis 支持数据的备份。Redis支持master-slave模式的数据备份。 Redis 数据结构 String （字符串） List （列表） Hash（散列） Set （集合） SortedSet （有序集合） HyperLogLog Redis 各种数据类型的使用场景举例分析 https://mengkang.net/356.html Redis 操作命令参考： Redis 命令参考 http://redisdoc.com/index.html Redis 命令速查手册https://raw.githubusercontent.com/huangz1990/redis-cheatsheet/master/redis-cheatsheet.pdf Redis 的一些配置/命令配置表示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112==配置文件全解=====基本配置daemonize no 是否以后台进程启动databases 16 创建database的数量(默认选中的是database 0)save 900 1 #刷新快照到硬盘中，必须满足两者要求才会触发，即900秒之后至少1个关键字发生变化。save 300 10 #必须是300秒之后至少10个关键字发生变化。save 60 10000 #必须是60秒之后至少10000个关键字发生变化。stop-writes-on-bgsave-error yes #后台存储错误停止写。rdbcompression yes #使用LZF压缩rdb文件。rdbchecksum yes #存储和加载rdb文件时校验。dbfilename dump.rdb #设置rdb文件名。dir ./ #设置工作目录，rdb文件会写入该目录。==主从配置slaveof &lt;masterip&gt; &lt;masterport&gt; 设为某台机器的从服务器masterauth &lt;master-password&gt; 连接主服务器的密码slave-serve-stale-data yes # 当主从断开或正在复制中,从服务器是否应答slave-read-only yes #从服务器只读repl-ping-slave-period 10 #从ping主的时间间隔,秒为单位repl-timeout 60 #主从超时时间(超时认为断线了),要比period大slave-priority 100 #如果master不能再正常工作，那么会在多个slave中，选择优先值最小的一个slave提升为master，优先值为0表示不能提升为master。repl-disable-tcp-nodelay no #主端是否合并数据,大块发送给slaveslave-priority 100 从服务器的优先级,当主服挂了,会自动挑slave priority最小的为主服===安全requirepass foobared # 需要密码rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 #如果公共环境,可以重命名部分敏感命令 如config===限制maxclients 10000 #最大连接数maxmemory &lt;bytes&gt; #最大使用内存maxmemory-policy volatile-lru #内存到极限后的处理volatile-lru -&gt; LRU算法删除过期keyallkeys-lru -&gt; LRU算法删除key(不区分过不过期)volatile-random -&gt; 随机删除过期keyallkeys-random -&gt; 随机删除key(不区分过不过期)volatile-ttl -&gt; 删除快过期的keynoeviction -&gt; 不删除,返回错误信息#解释 LRU ttl都是近似算法,可以选N个,再比较最适宜T踢出的数据maxmemory-samples 3====日志模式appendonly no #是否仅要日志appendfsync no # 系统缓冲,统一写,速度快appendfsync always # 系统不缓冲,直接写,慢,丢失数据少appendfsync everysec #折衷,每秒写1次no-appendfsync-on-rewrite no #为yes,则其他线程的数据放内存里,合并写入(速度快,容易丢失的多)auto-AOF-rewrite-percentage 100 当前aof文件是上次重写是大N%时重写auto-AOF-rewrite-min-size 64mb aof重写至少要达到的大小====慢查询slowlog-log-slower-than 10000 #记录响应时间大于10000微秒的慢查询slowlog-max-len 128 # 最多记录128条====服务端命令time 返回时间戳+微秒dbsize 返回key的数量bgrewriteaof 重写aofbgsave 后台开启子进程dump数据save 阻塞进程dump数据lastsave slaveof host port 做host port的从服务器(数据清空,复制新主内容)slaveof no one 变成主服务器(原数据不丢失,一般用于主服失败后)flushdb 清空当前数据库的所有数据flushall 清空所有数据库的所有数据(误用了怎么办?)shutdown [save/nosave] 关闭服务器,保存数据,修改AOF(如果设置)slowlog get 获取慢查询日志slowlog len 获取慢查询日志条数slowlog reset 清空慢查询info []config get 选项(支持*通配)config set 选项 值config rewrite 把值写到配置文件config restart 更新info命令的信息debug object key #调试选项,看一个key的情况debug segfault #模拟段错误,让服务器崩溃object key (refcount|encoding|idletime)monitor #打开控制台,观察命令(调试用)client list #列出所有连接client kill #杀死某个连接 CLIENT KILL 127.0.0.1:43501client getname #获取连接的名称 默认nilclient setname &quot;名称&quot; #设置连接名称,便于调试====连接命令===auth 密码 #密码登陆(如果有密码)ping #测试服务器是否可用echo &quot;some content&quot; #测试服务器是否正常交互select 0/1/2... #选择数据库quit #退出连接 关于 Redis 的持久化Redis 中有两种方法进行持久化，一种是快照，一种是Append-only。 快照Redis 以快照的形式将数据保存到一个二进制文件中（dump.rdb，名字可更改），在配置在N秒之内，至少发生M次修改则抓快照到磁盘（配置项：save N M）。我们也可以手动执行save 或者 bgsave（异步）做快照。 优点：不会太影响性能 缺点：Redis 挂掉后，最近的数据会丢失。当业务量很大时，会丢失很多数据（丢失数据的多少取决于你 save 策略的配置）。 Append-only使用 Append-only 方法（Redis 配置项：appendonly yes/no），Redis 可以每执行一个命令或者每隔1秒，都会添加到 AOF 文件中（取决于 Redis 配置项：appendfsync everysec/always/no）。当 Redis 关闭后，将会读取 AOF 文件进行“重放”以恢复到关闭时刻的数据。 优点：丢失数据较少 缺点：较影响 Redis 性能 我们一般将 快照 + AOF 结合起来做数据的同步。 Redis 同步机制Redis 可以使用主从同步，从从同步。第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存 buffer，待完成后将 rdb 文件全量同步到复制节点，复制节点接受完成后将 rdb 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 Redis 事务Redis 开启事务后（执行 multi）后，执行 Redis 命令 后，会将 Redis 执行命令放到队列里，并不真正执行，执行 exec 后，会出现有的 Redis 命令执行成功，有的执行失败。Redis 中的事务不像 mysql 的事务，有一个命令执行失败，commit后，一组 sql 操作全部执行失败、回滚操作。 使用 discard 会清空事务队列里的 Redis 命令，不执行 Redis 命令。 1234567891011121314#开启事务&gt; multi#提交事务&gt; exec#取消执行Redis命令&gt; discard#监视 key 值的变化, 如果key发生变化，事务取消&gt; watch key#取消监视 key 的变化&gt; unwatch 使用 watch命令 示例： 监控工具 sentinelSentinel不断与master通信,获取master的slave信息.监听master与slave的状态如果某slave失效,直接通知master去除该slave. PHP 操作 RedisPHP 操作 Redis，可查看 phpredis 的 github 仓库：https://github.com/phpredis/phpredis Python 中操作 RedisRedis 客户端工具 Redis的使用场景 会话缓存 热点数据缓存 队列 排行榜/计数器 发布/订阅 其它链接Redis在线测试 http://try.redis.io/ 天下无难试之Redis面试刁难大全 https://mp.weixin.qq.com/s/507jyNbL4xCkxyW6Xk15Xg]]></content>
      <tags>
        <tag>NOSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些Linux基本命令与其它相关]]></title>
    <url>%2F2018%2F08%2F16%2F%E4%B8%80%E4%BA%9BLinux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E4%B8%8E%E5%85%B6%E5%AE%83%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[Linux命令文件查找 findfind 参数很多，本文只介绍几个常用的 -name 按名字查找 -type 按类型 -atime 访问时间 123find . -atime 3 -type f -print // 列入当前目录下前3天访问过的文件find . -type d -print // 只列出所有目录find / -name &quot;test.txt&quot; 查找test.txt文件 字符替换 tr将字符转换为大写 1cat test.txt | tr a-z A-Z 文本替换 sed移除空白行，加上-i选项表示将更改写入文件 统计 wc123wc -l file 统计行数wc -w file // 统计单词数wc -c file // 统计字符数 1sed &apos;/^$/d&apos; file crontab定时任务过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或shell脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常适合周期性的日志分析或数据备份等工作。 crontab的文件格式 分 时 日 月 星期 要运行的命令 第1列分钟0～59第2列小时0～23（0表示子夜）第3列日1～31第4列月1～12第5列星期0～7（0和7表示星期天）第6列要运行的命令 实例： 1234* * * * * command # 每1分钟执行command命令3,15 * * * * command # 每小时第三分钟和第五分钟执行3,15 8-11 * * * command #在上午8点到11点的第3和第15分钟执行3,15 8-11 */2 * * command # 每隔两天的上午8点到11点的第3和第15分钟执行 阅读资料Linux中more和less命令用法 https://www.cnblogs.com/aijianshi/p/5750911.html AWK程序设计指南 https://awk.readthedocs.io/en/latest/chapter-one.html 命令手册 http://www.runoob.com/linux/linux-command-manual.html 鸟哥网站：http://linux.vbird.org/ 鸟哥的 Linux 私房菜：http://cn.linux.vbird.org/ Linux在线模拟器：http://cb.vu/ （手册：http://cb.vu/unixtoolbox_zh_CN.xhtml）]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>AWK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB入门]]></title>
    <url>%2F2018%2F08%2F16%2FMongoDB%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Mongodb是个开源的，高性能的面向文档的数据库，是为了解决关系数据库schema强约束的问题而产生的。Mongodb没有schema, 经常用JSON格式存储数据。 优点 新增字段简单，直接在程序中新增字段就可以，无须像关系数据库一样先创建表结构。 可以方便的存储复杂的数据。在关系数据库中一条数据需要关联存储在N个表中，在Mongodb中只需一行JSON格式的数据就可描述。 支持丰富的数据类型。 缺点 无法实现关系数据库的JOIN操作。 不支持SQL查询 MongoDB的一些概念SQL术语/概念 MongoDB术语/概念 解释/说明database database 数据库table collection 数据库表/集合row document 数据记录行/文档column field 数据字段/域index index 索引table joins 表连接，MongoDB不支持primary key primary key 主键,MongoDB自动将_id字段设置为主键 使用场景MongoDB适合复杂数据结构、大尺寸的文档化格式数据的存储和查询，可作为缓存，提高系统性能。对一些需要强事务性的系统还是关系型数据库合适，MongoDB不太合适。 学习资料 https://www.mongodb.com/ http://www.runoob.com/mongodb/mongodb-tutorial.html https://elemefe.gitbooks.io/mongodb/content/]]></content>
      <tags>
        <tag>MongoDB</tag>
        <tag>NOSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用websocket替代ajax加快网站访问速度]]></title>
    <url>%2F2018%2F08%2F16%2F%E4%BD%BF%E7%94%A8websocket%E6%9B%BF%E4%BB%A3ajax%E5%8A%A0%E5%BF%AB%E7%BD%91%E7%AB%99%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[一个使用websocket技术的实例之前「17CE」网址：http://www.17ce.com 测速使用 ajax 轮询需要多个 http 请求才能获取测速结果，现在测速发现快了很多，查看网络请求发现使用了 websocket 请求，只需要一次 websocket 请求就可以获取结果。 使用 ajax 轮询： 共有 15 个请求 使用 websocket： 共有 5 个请求 ajax 轮询在不断地建立 http 连接，然后等待服务端处理，非常被动， 服务器也不能主动地发送消息给客户端。http 的每一次请求与响应结束后，服务器将客户端信息全部丢弃，下次请求，必须携带身份信息(cookie)，非常费时。使用 websocket 建立一次链接就可以了，服务器和客户端可以互相发信息。 查看网页代码看是如何实现的： 1.首先加载js文件定义websocket对象： js文件：https://www.17ce.com/smedia/js/ws.min.js?ver=20180613 2.使用websocket获取测速结果推送 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 点击测速时会调用ajax_check()function ajax_check(pos,type,sid)&#123; var res = check_verify(); //使用ajax获取权限数据 if(res.rt)&#123; . . . reqWS(&apos;wsapi.17ce.com:8001/socket/?&apos; + setUrlK(res.data)); &#125;else&#123; alert(res.message); check_end(); &#125;&#125;// 发送websocket请求function reqWS(url)&#123; ws.init(&#123; url: url // 后台接口地址 &#125;).connect(); ws.onmessage = function(message) &#123; var res = &quot;string&quot; == typeof(message.data) ? JSON.parse(message.data) : message.data; // console.dir(&quot;TaskAccept receive:&quot; + JSON.stringify(res)); if(res[&apos;rt&apos;] == 1 &amp;&amp; res[&apos;msg&apos;] == &apos;login ok&apos;)&#123; login = true; s_time = new Date(); timeoutFlag = true; send_tx(); //发送请求 checkon(); // 测速中 隐藏div return &#125;else if(res[&apos;rt&apos;] == 1)&#123; . . . &#125;else&#123; alert(JSON.stringify(res.error)); &#125; check_end(); &#125; ws.onopen = function() &#123; // send_tx(); &#125;;&#125;//json转url参数 setUrlK(&#123;name:&quot;a&quot;&#125;,true编码)function setUrlK(ojson) &#123; var s=&apos;&apos;,name, key; for(var p in ojson) &#123; if(!ojson[p]) &#123;return null;&#125; if(ojson.hasOwnProperty(p)) &#123; name = p &#125;; key = ojson[p]; s += &quot;&amp;&quot; + name + &quot;=&quot; + encodeURIComponent(key); &#125;; return s.substring(1,s.length);&#125;;//使用ws.send()向服务端发送数据function send_tx()&#123; . . . var postdata = getPostdata(); ws.send(JSON.stringify(postdata)) . . .&#125; 服务端（PHP）websocket实现方案「Workerman」https://github.com/walkor/workerman 「Swoole」https://github.com/swoole/swoole-src 参考资料http://www.ruanyifeng.com/blog/2017/05/websocket.html]]></content>
      <tags>
        <tag>php</tag>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Beautifulsoup抓取91ud小程序]]></title>
    <url>%2F2018%2F08%2F15%2F%E4%BD%BF%E7%94%A8Beautifulsoup%E6%8A%93%E5%8F%9691ud%E5%B0%8F%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[环境部署/依赖包安装安装virtualenv使用virtualenv为每个项目建立不同的/独立的Python环境，减少软件冲突。 安装方法 1pip install -i https://pypi.douban.com/simple virtualenv 安装virtualenvwrappervirtualenvwrapper 是一个建立在 virtualenv 上的工具，通过它可以方便的创建/激活/管理/销毁虚拟环境。 安装方法： 1pip install -i https://pypi.douban.com/simple virtualenvwrapper 新建虚拟环境/安装软件12345678910# 新建虚拟环境mkvirtualenv --python=/usr/local/bin/python3 91ud-spider# 切换虚拟环境workon 91ud-spider# 安装依赖包pip install -i https://pypi.douban.com/simple requestspip install -i https://pypi.douban.com/simple mysqlclientpip install -i https://pypi.douban.com/simple beautifulsoup4 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156# -*- coding: utf-8 -*-__author__ = &apos;yunshu&apos;import requestsimport osimport jsonimport timeimport hashlibimport randomimport MySQLdbfrom bs4 import BeautifulSoupfrom urllib import parse&apos;&apos;&apos;使用Beautifulsoup抓取91ud小程序Beautifulsoup文档参考：http://www.jb51.net/article/65287.htmpython版本：3.6&apos;&apos;&apos;headers = &#123; &apos;User-Agent&apos;:&apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&apos;&#125;conn = MySQLdb.connect(host=&apos;localhost&apos;, user=&apos;root&apos;, passwd=&apos;123456&apos;, db=&apos;spiders&apos;, charset=&apos;utf8&apos;)cursor = conn.cursor()def spider(minpage=1, maxpage=2): content = [] index = minpage*48 for page in range(minpage, maxpage): if page == 1: request_url = &apos;http://www.91ud.com/app/&apos; else: request_url = &apos;http://www.91ud.com/app/%d&apos; % page r = requests.get(request_url, headers=headers) if r.status_code == 200: soup = BeautifulSoup(r.text, &apos;lxml&apos;) items = soup.find_all(&apos;li&apos;, attrs=&#123;&apos;class&apos;:&apos;item&apos;&#125;) for item in items: index = index + 1 detail_url = item.find(&apos;a&apos;, attrs=&#123;&apos;class&apos;:&apos;avatar&apos;&#125;).get(&apos;href&apos;) detail_url = parse.urljoin(r.url, detail_url) detail = get_detail(detail_url) detail[&apos;order&apos;] = index insert_db(detail) content.append(detail) else: print(r.status_code) # r.raise_for_status() print(&apos;fetch %s&apos; % request_url) time.sleep(random.randint(1,3)) conn.close() with open(&apos;q1ud.json&apos;, &apos;w&apos;, encoding=&apos;utf-8&apos;) as fp: json.dump(content, fp=fp, indent=4, ensure_ascii=False)def get_detail(url): detail = &#123;&#125; r = requests.get(url, headers=headers) if r.status_code == 200: soup = BeautifulSoup(r.text, &apos;lxml&apos;) title = soup.find(&apos;h1&apos;).get_text() tag_list = [] avatar = soup.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;:&apos;intro&apos;&#125;).find(&apos;img&apos;).get(&apos;src&apos;) tags = soup.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;:&apos;tags&apos;&#125;).find_all(&apos;a&apos;) qrcode = soup.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;:&apos;qrcode&apos;&#125;).find(&apos;img&apos;).get(&apos;src&apos;) category = soup.find(&apos;ul&apos;, attrs=&#123;&apos;class&apos;:&apos;info&apos;&#125;).find(&apos;a&apos;).get(&apos;href&apos;).strip(&apos;/&apos;) os_infos = soup.find(&apos;ul&apos;, attrs=&#123;&apos;class&apos;:&apos;info&apos;&#125;).find_all(&apos;strong&apos;) # 待过滤处理html，去掉超链接等 desc = soup.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;:&apos;description&apos;&#125;).find(&apos;p&apos;).prettify() os_info = os_infos[3].get_text() create_time = os_infos[1].get_text() for tag in tags: tag_list.append(tag.get_text()) detail[&apos;title&apos;] = title detail[&apos;avatar&apos;] = avatar detail[&apos;tag_list&apos;] = &apos;,&apos;.join(tag_list) detail[&apos;qrcode&apos;] = qrcode detail[&apos;category&apos;] = category detail[&apos;create_time&apos;] = create_time detail[&apos;os_info&apos;] = os_info detail[&apos;desc&apos;] = desc detail[&apos;url&apos;] = r.url detail[&apos;url_object_id&apos;] = get_md5(url) path = get_save_path(&apos;images&apos;) if download_image(detail[&apos;qrcode&apos;], path): detail[&apos;local_image&apos;] = path + &apos;/&apos; + qrcode.split(&apos;/&apos;)[-2] + &apos;.jpg&apos; else: detail[&apos;local_image&apos;] = &apos;&apos; path = get_save_path(&apos;avatar&apos;) if download_image(detail[&apos;avatar&apos;], path): detail[&apos;local_avatar&apos;] = path + &apos;/&apos; + avatar.split(&apos;/&apos;)[-2] + &apos;.jpg&apos; else: detail[&apos;local_avatar&apos;] = &apos;&apos; else: print(&apos;fetch url:%s error&apos; % url) return detaildef get_save_path(path): subdir = (str(random.randint(1, 20))) if not os.path.exists(path + &apos;/&apos; + subdir): os.makedirs(path + &apos;/&apos; + subdir) return path + &apos;/&apos; + subdirdef insert_db(detail): sql = &quot;insert into 91ud(title,avatar,local_image,local_avatar,tag_list,qrcode,category,os_info, `desc`, create_at, `order`,`url`,`url_object_id`) values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s, %s,%s) ON DUPLICATE KEY UPDATE title=%s&quot; vals = (detail[&apos;title&apos;], detail[&apos;avatar&apos;], detail[&apos;local_image&apos;], detail[&apos;local_avatar&apos;], detail[&apos;tag_list&apos;], detail[&apos;qrcode&apos;], detail[&apos;category&apos;], detail[&apos;os_info&apos;], detail[&apos;desc&apos;], detail[&apos;create_time&apos;], detail[&apos;order&apos;],detail[&apos;url&apos;], detail[&apos;url_object_id&apos;],detail[&apos;title&apos;]) cursor.execute(sql, vals) conn.commit()def download_image(url, path): print(&quot;download image %s&quot; % url) get_file_name = lambda url: os.path.join(path, url.split(&apos;/&apos;)[-2] + &apos;.jpg&apos;) headers[&apos;Referer&apos;] = url response = requests.get(url, headers=headers) if response.status_code == 200: file_name = get_file_name(url) with open(file_name, &apos;wb&apos;) as f: f.write(response.content) return True else: print(&apos;fetch image %s error&apos; % url) return Falsedef get_md5(url): # 如果是unicode字符串，则进行utf-8编码 if isinstance(url, str): url = url.encode(&apos;utf-8&apos;) m = hashlib.md5() m.update(url) return m.hexdigest()if __name__ == &apos;__main__&apos;: spider(1, 2) 代码链接：https://github.com/pythondev-cn/pythonspiders/blob/master/91ud/91ud.py]]></content>
  </entry>
  <entry>
    <title><![CDATA[《高性能MySQL》读书笔记]]></title>
    <url>%2F2018%2F08%2F01%2F%E3%80%8A%E9%AB%98%E6%80%A7%E8%83%BDMySQL%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Schema与数据类型优化选择的优化的数据类型 一般情况下，应该尽量使用可以正确存储数据的最小数据类型。更小的数据类型通常更快，因为他们占用更少的磁盘、内存和CPU缓存，并且处理时需要的CPU周期更少。 使用简单的数据类型。例如，整型比字符串操作代价更低，因为字符串集和校对规则（排序规则）使字符比较比整形比较更复杂。另外，应该使用应该使用mysql的内建类型而不是字符串存储日期和时间，应该使用整形存储IP地址。 尽量避免NULL值。使用NULL的列会使用更多的存储空间，在MySQL里需要特殊处理。当可为NULL的列被索引时，每个索引需要一个额外的字节，在MyISAM里甚至可能导致固定大小的所有（例如只有一个整形列的索引）变成可大可小的索引。通过把可为NULL的列改为NOT NULL带来的性能提升比较小，如果不确定这回导致性能瓶颈问题不必要首先修改。如果计划在列上建索引，就尽量避免设计成可为NULL的列。 MySQL为了兼容性支持了很多别名，例如INTEGER、BOOL以及NUMERIC, 他们只是别名。这些别名不会影响性能。如果建表时采用数据类型的别名，用SHOW CREATE TABLE可以发现报告的是基本数据类型，而不是别名。 整型类型 整型类型有这几种：TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT。分别使用8，16， 24， 32， 64位存储空间。他们可以存储的范围从-2(n-1) ~ 2(n-1)-1 （-2的n-1次方到2的n-1次方-1），其中N是存储空间的位数。 整型类型有可选的UNSIGNED属性，表示不允许负值， 这大致可以使得正数的上限提高一倍。例如TINYINT UNSIGNED可以存储的范围是0~255。 MySQL可以为整数类型指定宽度，例如INT(11)，对大多数应用来说这是没有意义的：它不会限制值的合法范围，只是规定了MySQL的一些交互工具（例如MySQL命令行客户端）用来显示字符的个数。对于存储和计算来说INT(11)和INT(20)是相同的。 实数类型 FLOAT和DOUBLE类型致辞使用标准的浮点预算进行近似计算。 DECIMAL类型用于存储精确的小数。在MySQL 5.0以及更高版本中，DECIMAL类型支持精度计算。因为CPU不支持对DECIMAL的直接计算，所以在MySQL 5.0以及更高的版本中，MySQL服务器自身实现了DECIMAL的高精度计算。相对而言，CPU直接支持原生浮点计算，所以浮点运算明显更快。 对于DECIMAL列，可以指定小数点前后所允许的最大位数。MySQL 5.0和更高版本将数字打包保存到一个二进制字符串中（每4个字节存9个数字）。例：DECIMAL(18，9）将存储9个字节（其中小数点占用1个字节）。 浮点类型在存储同样范围的值时，通常比DECIMAL使用更少的存储空间。FlOAT使用4个字节存储。DOUBLE占用8个字节，相比FLOAT有更高的精度和更大的范围。MySQL使用DOUBLE作为内部浮点计算的类型。 因为需要额外的空间和计算开销，所以应该尽量对小数进行精确计算时才使用DECIMAL—例如存储财务数据。一个技巧是用BIGINT存储DECIMAL数值（只需要将数值乘以相应的倍数即可），避免浮点存储计算不精确和DECIMAL精确计算代价高的问题。 字符串类型 VARCHAR 可以存储可变长字符串，是最常见的字符串数据类型。它比定长类型更节省空间，因为它使用必要的空间。有一种情况例外，如果MySQL表使用ROW_FORMAT=FIXED创建的话，每一行都会使用定长存储，这会很浪费空间。 VARCHAR需要使用1个或者2个额外的字节记录字符串的长度；如果列的最大长度小于或者等于255个字节，则只使用1个字节，否则使用2个字节。 CHARCHAR类型是定长的。当存储CHAR值时，MySQL会删除所有的末尾空格。CHAR值适合存储定长的字段，或者说所有值都接近同一个长度（这种情况下，使用CHAR值存储不容易产生碎片）。 BINARY和VARBINARY这两种类型存储的是二进制字符串。二进制字符串使用字节码存储。BINARY采用\0(零字节）来填充使得长度达到指定的长度。当需要存储二进制数据，并且希望MySQL使用字节码而不是字符进行比较时，可以使用二进制类型。 BLOB和TEXT类型BLOB和TEXT都是为存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储。BLOB类型包含了TINYBLOB、SMALLBLOB、BLOB、MEDIUMBLOB、LONGBLOB。BLOB是SMALLBLOB的同义词，TEXT是SMALLTEXT的同义词。 BLOB类型存储的是二进制数据，没有排序规则或者数据集，而TEXT类型有字符集和排序规则。 枚举类型枚举类型可以把一些不重复的字符串存储在一个预定义的集合中。MySQL在内部将每个值在列表中的位置保存为整数，在表的.frm文件中保存“数字 - 字符串”映射关系的“查找表”。另外，枚举字段排序是安装内存存储的整数进行排序的。 缺点：字符串列表时固定的，添加或者删除元素，需要ALTER TABLE。所以未来会改变字符串的字段，使用枚举并不合适。 日期和时间类型MySQL提供两种相似的时间类型：DATETIME和TIMESTAMP，两种时间类型支持存储的最小粒度为秒（MariaDB支持微妙级别的时间类型）。 DATETIME这个类型能保存大范围的值，从1001年到9999年。存储的时间与时区无关，占用8个字节的存储空间。 TIMESTAMP这个类型保存的范围从1970年到2038年，占用4个字节的存储空间。TIMESTAMP显示的值依赖于失去。MySQL服务器、操作系统，以及客户端连接都有时区设置。 推荐尽量使用TIMESTAMP类型，因为它比DATETIME的空间利用率高。此外不推荐使用整型存储时间，不方便处理。 如果要存储微妙级别的时间，可以使用BIGINT存储微妙级别的时间戳，或者使用DOUBLE类型存储秒之后的小数部分。 选择标识符 为标识列选择数据类型时，应该选择跟关联表中的对应列一样的类型。类型之间要精确匹配，包括想UNSIGNED这样的属性。 应当避免使用字符串类型作为标识符，因为他们很消耗空间并且通常比数字慢。推荐使用整数作为标识符。 一些其它建议如存储ipv4地址，使用UNSIGNED INT存储，它比使用CHAR(15)有更高的空间效率。使用inet_aton可将把ip转为无符号整型，使用inet_ntoa可把整型的ip转为电地址。 MySQL schema设计的一些指导原则 一个表不要有太多的列 减少表关联 适度使用NULL值，减少应用复杂程度，避免引入奇怪的BUG。 创建高性能的索引索引的类型B-Tree 索引大家一般说索引的时候， 如果没有特别指明类型， 多半说的是B-Tree索引，它使用B-Tree数据结构来存储数据。 B-Tree通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同。 B-Tree索引使用与全键值、键值范围或者键值前缀前缀查找。其中键前缀查找只适用于根据最左前缀的查找。对如下类型的查询有效。 全值匹配 全值匹配值的是和索引中的所有列进行匹配。 匹配最左前缀 查询只使用到索引的第一列。 匹配列前缀 只匹配某列的值的开头部分。 如使用like查询索引匹配第一列的前面部分字符。 匹配范围值 使用B-Tree索引的限制 如果不是按照索引的最左列开始查找，则无法使用索引。 （查询必须包含最左列，并且不能查询左列以某字母结尾的行，才能使用到索引） 哈希索引哈希索引（hash index）基于哈希表实现，只有精确匹配所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算出一个哈希码（hash code）,哈希码是一个较小的值，并且在不同的键值的行计算出来的哈希码也不一样。哈希索引将所有的哈希码存储在所有中，同时在哈希表中保存指向每个数据行的指针。 哈希索引的限制 哈希索引数据不是按照索引值顺序存储的，无法用于排序。 哈希索引值只支持等值比较查询。 可以使用SRC32()做为哈希函数存储哈希值，但是如果数据量很大，会出现哈希冲突的情况。 不要使用SHA1()和MD5()作为哈希函数。这两个函数计算出来的哈希值是一个非常长的字符串，会浪费大量的空间，比较时也比较慢。 要解决冲突问题，必须在where条件中带入哈希值和对应的列值。 select world,crc from words where cc=CRC32(&#39;gnu&#39;) and word=&#39;gnu&#39; 还可以使用FNV64()函数作为哈希函数解决冲突。FNV64()哈希值为64位，速度快，且冲突比CRC32()要少的多。 全文索引全文索引必须要使用关键词MATCH和AGAINST，而不是使用WHERE进行搜索。]]></content>
  </entry>
  <entry>
    <title><![CDATA[thinkphp5 “$this->redirect()” 到底经历了啥]]></title>
    <url>%2F2018%2F04%2F07%2Fthinkphp5-source-reading%2F</url>
    <content type="text"><![CDATA[redirect方法，可以在自定义的控制器实现跳转的功能。看thinkphp 5.1源码发现它是在在jump trait中定义的一个方法。 Controller.php 12345678910111213141516171819202122232425...use traits\controller\Jump;class Controller&#123; use Jump; /** * 视图类实例 * @var \think\View */ protected $view; /** * Request实例 * @var \think\Request */ protected $request;...&#125; jump.php 可以看到它抛出一个异常 12345678910111213141516171819202122232425262728293031323334353637&lt;?php...namespace traits\controller;use think\Container;use think\exception\HttpResponseException;use think\Response;use think\response\Redirect;trait Jump&#123; . . . protected function redirect($url, $params = [], $code = 302, $with = []) &#123; $response = new Redirect($url); if (is_integer($params)) &#123; $code = $params; $params = []; &#125; $response-&gt;code($code)-&gt;params($params)-&gt;with($with); throw new HttpResponseException($response); &#125; . . . &#125; 查看HttpResponseException可以发现它是Excepton的子类 HttpResponseException.php 1234567891011121314151617181920&lt;?phpnamespace think\exception;use think\Response;class HttpResponseException extends \RuntimeException&#123; protected $response; public function __construct(Response $response) &#123; $this-&gt;response = $response; &#125; public function getResponse() &#123; return $this-&gt;response; &#125;&#125; RuntimeException是SPL中的类,它继承Exception12class RuntimeException extends Exception &#123;&#125; 到此我们知道了redirect()方法其实是抛出一个异常，那它是在哪里调用然后输出（跳转）呢？ 从入口文件index.php开始。发现先加载base.php，然后执行App类的run方法。然后调用返回对象的send方法 12345678910&lt;?phpnamespace think;// 加载基础文件require __DIR__ . &apos;/../thinkphp/base.php&apos;;// 支持事先使用静态方法设置Request对象和Config对象// 执行应用并响应Container::get(&apos;app&apos;)-&gt;run()-&gt;send(); App类,发现它catch了一个HttpResponseException，返回Redirect类型的Response 对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115&lt;?phpnamespace think;use think\exception\ClassNotFoundException;use think\exception\HttpResponseException;use think\route\Dispatch;/** * App 应用管理 */class App implements \ArrayAccess&#123; const VERSION = &apos;5.1.5&apos;; . . . // 执行应用程序 public function run() &#123; // 初始化应用 $this-&gt;initialize(); try &#123; if ($this-&gt;bind) &#123; // 模块/控制器绑定 $this-&gt;route-&gt;bind($this-&gt;bind); &#125; elseif ($this-&gt;config(&apos;app.auto_bind_module&apos;)) &#123; // 入口自动绑定 $name = pathinfo($this-&gt;request-&gt;baseFile(), PATHINFO_FILENAME); if ($name &amp;&amp; &apos;index&apos; != $name &amp;&amp; is_dir($this-&gt;appPath . $name)) &#123; $this-&gt;route-&gt;bind($name); &#125; &#125; // 读取默认语言 $this-&gt;lang-&gt;range($this-&gt;config(&apos;app.default_lang&apos;)); if ($this-&gt;config(&apos;app.lang_switch_on&apos;)) &#123; // 开启多语言机制 检测当前语言 $this-&gt;lang-&gt;detect(); &#125; $this-&gt;request-&gt;langset($this-&gt;lang-&gt;range()); // 加载系统语言包 $this-&gt;lang-&gt;load([ $this-&gt;thinkPath . &apos;lang/&apos; . $this-&gt;request-&gt;langset() . &apos;.php&apos;, $this-&gt;appPath . &apos;lang/&apos; . $this-&gt;request-&gt;langset() . &apos;.php&apos;, ]); // 监听app_dispatch $this-&gt;hook-&gt;listen(&apos;app_dispatch&apos;); // 获取应用调度信息 $dispatch = $this-&gt;dispatch; if (empty($dispatch)) &#123; // 进行URL路由检测 $dispatch = $this-&gt;routeCheck(); &#125; // 记录当前调度信息 $this-&gt;request-&gt;dispatch($dispatch); // 记录路由和请求信息 if ($this-&gt;debug) &#123; $this-&gt;log(&apos;[ ROUTE ] &apos; . var_export($this-&gt;request-&gt;routeInfo(), true)); $this-&gt;log(&apos;[ HEADER ] &apos; . var_export($this-&gt;request-&gt;header(), true)); $this-&gt;log(&apos;[ PARAM ] &apos; . var_export($this-&gt;request-&gt;param(), true)); &#125; // 监听app_begin $this-&gt;hook-&gt;listen(&apos;app_begin&apos;); // 请求缓存检查 $this-&gt;request-&gt;cache( $this-&gt;config(&apos;app.request_cache&apos;), $this-&gt;config(&apos;app.request_cache_expire&apos;), $this-&gt;config(&apos;app.request_cache_except&apos;) ); // 执行调度 $data = $dispatch-&gt;run(); &#125; catch (HttpResponseException $exception) &#123; $data = $exception-&gt;getResponse(); &#125; $this-&gt;middlewareDispatcher-&gt;add(function (Request $request, $next) use ($data) &#123; // 输出数据到客户端 if ($data instanceof Response) &#123; $response = $data; &#125; elseif (!is_null($data)) &#123; // 默认自动识别响应输出类型 $isAjax = $request-&gt;isAjax(); $type = $isAjax ? $this-&gt;config(&apos;app.default_ajax_return&apos;) : $this-&gt;config(&apos;app.default_return_type&apos;); $response = Response::create($data, $type); &#125; else &#123; $response = Response::create(); &#125; return $response; &#125;); $response = $this-&gt;middlewareDispatcher-&gt;dispatch($this-&gt;request); // 监听app_end $this-&gt;hook-&gt;listen(&apos;app_end&apos;, $response); return $response; &#125; . . .&#125; 继续看Redirect类父类Response的send方法。它设置了header头等 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?php namespace think;use think\response\Redirect as RedirectResponse;class Response&#123; . . . /** * 发送数据到客户端 * @access public * @return void * @throws \InvalidArgumentException */ public function send() &#123; // 监听response_send Container::get(&apos;hook&apos;)-&gt;listen(&apos;response_send&apos;, $this); // 处理输出数据 $data = $this-&gt;getContent(); // Trace调试注入 if (Container::get(&apos;env&apos;)-&gt;get(&apos;app_trace&apos;, Container::get(&apos;app&apos;)-&gt;config(&apos;app.app_trace&apos;))) &#123; Container::get(&apos;debug&apos;)-&gt;inject($this, $data); &#125; if (200 == $this-&gt;code &amp;&amp; $this-&gt;allowCache) &#123; $cache = Container::get(&apos;request&apos;)-&gt;getCache(); if ($cache) &#123; $this-&gt;header[&apos;Cache-Control&apos;] = &apos;max-age=&apos; . $cache[1] . &apos;,must-revalidate&apos;; $this-&gt;header[&apos;Last-Modified&apos;] = gmdate(&apos;D, d M Y H:i:s&apos;) . &apos; GMT&apos;; $this-&gt;header[&apos;Expires&apos;] = gmdate(&apos;D, d M Y H:i:s&apos;, $_SERVER[&apos;REQUEST_TIME&apos;] + $cache[1]) . &apos; GMT&apos;; Container::get(&apos;cache&apos;)-&gt;tag($cache[2])-&gt;set($cache[0], [$data, $this-&gt;header], $cache[1]); &#125; &#125; if (!headers_sent() &amp;&amp; !empty($this-&gt;header)) &#123; // 发送状态码 http_response_code($this-&gt;code); // 发送头部信息 foreach ($this-&gt;header as $name =&gt; $val) &#123; header($name . (!is_null($val) ? &apos;:&apos; . $val : &apos;&apos;)); &#125; &#125; $this-&gt;sendData($data); if (function_exists(&apos;fastcgi_finish_request&apos;)) &#123; // 提高页面响应 fastcgi_finish_request(); &#125; // 监听response_end Container::get(&apos;hook&apos;)-&gt;listen(&apos;response_end&apos;, $this); // 清空当次请求有效的数据 if (!($this instanceof RedirectResponse)) &#123; Container::get(&apos;session&apos;)-&gt;flush(); &#125; &#125; . . .&#125; 最后应用终止时会执行shutdown处理方法。它在Error.php已经注册了shutdown方法为Error类的appShutdown方法 1234567891011121314151617&lt;?php class Error &#123; . . . public static function register() &#123; error_reporting(E_ALL); set_error_handler([__CLASS__, &apos;appError&apos;]); set_exception_handler([__CLASS__, &apos;appException&apos;]); register_shutdown_function([__CLASS__, &apos;appShutdown&apos;]); &#125; . . .&#125; appShutdown方法 123456789101112public static function appShutdown()&#123; if (!is_null($error = error_get_last()) &amp;&amp; self::isFatal($error[&apos;type&apos;])) &#123; // 将错误信息托管至think\ErrorException $exception = new ErrorException($error[&apos;type&apos;], $error[&apos;message&apos;], $error[&apos;file&apos;], $error[&apos;line&apos;]); self::appException($exception); &#125; // 写入日志 Container::get(&apos;log&apos;)-&gt;save();&#125; OK. 另：thinkphp 5.0源码阅读参考：https://www.kancloud.cn/zmwtp/tp5/155311]]></content>
      <tags>
        <tag>php</tag>
        <tag>thinkphp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库扩展]]></title>
    <url>%2F2018%2F04%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[复制和分离主从复制复制原理: master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； slave将master的binary log events拷贝到它的中继日志(relay log)； slave重做中继日志中的事件。 复制过程对于主服务器的影响非常有限。当存在多个从服务器同时从一个主武器进行复制的时候，主服务器的磁盘压力会有不同程度额增长，可以采用多级复制策略解决。 读写分离对于查询操作比较密集的站点，将读操作分配给从服务器，写操作分配给主服务器。 mysqlroute数据库反向代理mysqlroute工作在应用程序和mysql服务器之间，负责所有请求和响应数据的转发。mysqlroute会将应用的读请求分配到主服务器上，将写请求分配到从服务器上，最后将结果返回给应用，在开始时只需要对mysqlroute做一些配置即可。 也可以使用Mycat数据库中间件 垂直分区当数据库写操作频繁的站点来说，可以采用垂直分区来解决。 将不同类型的数据库转移到独立的数据库服务器上，然后又可以对分出去的数据库做主从复制来实现读写分离。 水平分区当通过垂直分区后，数据库的主服务器再次无法承受写操作压力时，我们可以将同一数据表中的记录通过特定的算法进行分离，分别保存到不同的数据库表中，从而可以部署到不同的服务器服务器上。 分区和分表在分区之前要先分表，分表只是单台数据库的优化策略。为了让数据库的可扩展，便需要考虑分区，将表迁移到其它的数据库服务器上。 分片策略分片字段的选择：一般选择数据表的主键，但得保证不能使用auto_increment自增类型，可以自己实现一个id生成器（使用redis可实现）。 哈希算法可以采用取模的方式，数据分布均匀，扩容要成倍扩容，2台服务器扩展到4台服务器。 范围会造成访问不均的情况。 时间适合归档性质的数据。 映射关系映射表维护比较麻烦。 分区反向代理 MyCAT 官网：http://www.mycat.io/ Spock Proxy 关系型数据库瓶颈 缓存 全文检索 方案1：xunsearch http://www.xunsearch.com/ 方案2：Elasticsearch Elasticsearch入门教程参考： http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html NOSQL]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站性能优化]]></title>
    <url>%2F2018%2F03%2F25%2F%E7%BD%91%E7%AB%99%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前端优化减少http请求数 图片地图。客户单图片地图可以使用map标签来实现。如果正在导航或者其他超链接中使用多个图片，将他们转换为图片地图是加速页面的最简单的方式。 CSS Sprites。将多幅图片合并成单独的图片。使用CSS的background-position属性，可以将HTML元素放置到背景图片期望的位置上。 内联图片。使用data:URL模式可以在Web页面中包含图片但无需额外的HTTP请求。 合并脚本和样式表。理想情况下，一个页面应该使用不多于一个脚本和样式表。 使用CDN存储前端资源CDN用于发布静态内容，如图片、脚本、样式和Flash。 可使用http://17ce.com这个网站网站使用CDN后在各地的响应速度。 添加Expires头充分利用浏览器缓存多域名访问前端资源使用单独的静态资源域名。资源数据的压缩压缩代码大小、图片大小，开启服务器gzip压缩优化首屏展示速度 延迟加载、异步加载 扩展阅读： 雅虎34条军规 Yslow Web性能测试插件 php优化使用opcode缓存opcode缓存简介 当解释器完成对脚本代码的分析后，便将它们生成可以直接运行的中间代码，也称为操作码（Operate Code，opcode）。Opcode cache的目地是避免重复编译，减少CPU和内存开销。如果动态内容的性能瓶颈不在于CPU和内存，而在于I/O操作，比如数据库查询带来的磁盘I/O开销，那么opcode cache的性能提升是非常有限的。 使用opcode缓存 从图中可以看出，使用了opcode缓存后，php代码的生命周期少了词典扫描和表达式（将PHP代码转换为语言片段[Tokens]）、解析文件（将Tokens转换成简单而有意义的表达式）、创建要执行的计算机代码（称为Opcode）几步。 opecode缓存-Zend OPcache安装使用PHP&gt;=5.5.0，php内置了OPcache,PHP小于5.5.0的话，要通过PCEL安装。 OPcache配置 123456789101112#检查脚本时间戳是否有更新的周期，以秒为单位。 设置为0会导致针对每个请求，OPcache都会检查脚本更新。opcache.revalidate_freq=60#如果启用，那么 OPcache 会每隔 opcache.revalidate_freq 设定的秒数 检查脚本是否更新。 如果禁用此选项，你必须使用 opcache_reset() 或者 opcache_invalidate() 函数来手动重置 OPcache，也可以 通过重启 Web 服务器来使文件系统更改生效opcache.validate_timestamps=1 #OPcache 哈希表中可存储的脚本文件数量上限。 真实的取值是在质数集合 &#123; 223, 463, 983, 1979, 3907, 7963, 16229, 32531, 65407, 130987 &#125; 中找到的第一个大于等于设置值的质数。 设置值取值范围最小值是 200，最大值在 PHP 5.5.6 之前是 100000，PHP 5.5.6 及之后是 1000000opcache.max_accelerated_files=1000#OPcache 的共享内存大小，以兆字节为单位。opcache.memory_consumption=512# 用来存储预留字符串的内存大小，以兆字节为单位。 PHP 5.3.0 之前的版本会忽略此配置指令。opcache.interned_strings_buffer=16#如果启用，则会使用快速停止续发事件。 所谓快速停止续发事件是指依赖 Zend 引擎的内存管理模块 一次释放全部请求变量的内存，而不是依次释放每一个已分配的内存块。opcache.fast_shutdown=1 PHP 7PHP 7相对比PHP 5.*,性能有了质的飞跃。PHP7相对于php5.6有2~3倍的性能提升。目前PHP的最新版本是PHP 7.2.5，相对于PHP 7.1也有部分性能提升。 性能评测文章参考： PHP的性能演进(从PHP5.0到PHP7.1的性能全评测PHP7.2、PHP7.1 性能对比 SWOOLE… php性能分析 xhui + tideways实践 tiways是一个测试php性能的php扩展，php版本要求是大于等于7.0。如果php版本小于7.0，可以使用xhprof扩展。xhgui用来展示测试数据，xhgui将数据保存到MongoDB。 安装tideways在ubuntu环境下： 1234echo &apos;deb http://s3-eu-west-1.amazonaws.com/qafoo-profiler/packages debian main&apos; &gt; /etc/apt/sources.list.d/tideways.listwget -qO - https://s3-eu-west-1.amazonaws.com/qafoo-profiler/packages/EEB5E8F4.gpg | sudo apt-key add -sudo apt-get updatesudo apt-get install tideways-php tideways-daemon 重启php-fpm，查看是否安装成功： 1sudo service php7.1-fpm restart 安装MongoDB123sudo apt-get install mongodbsudo apt-get install php-mongodbsudo /etc/init.d/mongodb start 安装xhgui123git clone https://github.com/laynefyc/xhgui-branch.gitcd xhgui-branchcomposer install 配置xhgui添加config/config.php,添加支持扩展为tideways 123return [ &apos;extension&apos; =&gt; &apos;tideways&apos;,]; MongoDB加索引1234567$ mongo &gt; use xhprof &gt; db.results.ensureIndex( &#123; &apos;meta.SERVER.REQUEST_TIME&apos; : -1 &#125; ) &gt; db.results.ensureIndex( &#123; &apos;profile.main().wt&apos; : -1 &#125; ) &gt; db.results.ensureIndex( &#123; &apos;profile.main().mu&apos; : -1 &#125; ) &gt; db.results.ensureIndex( &#123; &apos;profile.main().cpu&apos; : -1 &#125; ) &gt; db.results.ensureIndex( &#123; &apos;meta.url&apos; : 1 &#125; ) 配置nginx 1.要监控的应用 123456789101112131415161718 location ~ \.php$ &#123; fastcgi_split_path_info ^(.+\.php)(/.+)$; fastcgi_pass unix:/var/run/php/php7.1-fpm.sock; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; #加上下面的这两句 fastcgi_param TIDEWAYS_SAMPLERATE &quot;25&quot;; fastcgi_param PHP_VALUE &quot;auto_prepend_file=/home/vagrant/Code/xhgui/external/header.php&quot;; fastcgi_intercept_errors off; fastcgi_buffer_size 16k; fastcgi_buffers 4 16k; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300;&#125; 2.分析平台应用 12345678910#表示省略了一些nginx配置server &#123; listen 80; listen 443 ssl http2; server_name xhgui.app; root &quot;/home/vagrant/Code/xhgui/webroot&quot;; . . .&#125; 性能分析平台搭建效果 相关链接 ： https://github.com/tideways/php-xhprof-extension https://tideways.io/profiler/docs/setup/installation https://github.com/laynefyc/xhgui-branch.git 使用XHProf查找PHP性能瓶颈 Mysql优化表的设计优化 添加主键索引 innodb需要有一个主键，主键不要有业务用途。 表的字段类型选择 能选短整形，就不要选长整型 能选char就避免varchar 使用varchar类型的时候，长度够用就行 大字段考虑分开存储 字段适当冗余 索引的优化 索引不要建太多 在修改数据时，每个索引都要进行更新，降低写速度。 explain分析sql语句的执行计划 示例： 123456&gt; explain select * from typecho_contents where cid=40;+----+-------------+------------------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+------------------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| 1 | SIMPLE | typecho_contents | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | NULL |+----+-------------+------------------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ 重要列： type - 连接使用的类型 链接类型从最佳到最坏：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 解释： system:表仅有一行(=系统表)。这是const联接类型的一个特例。 const:表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const表很快,因为它们只读取一次! eq_ref:对于每个来自于前面的表的行组合,从该表中读取一行。这可能是最好的联接类型,除了const类型。 ref:对于每个来自于前面的表的行组合,所有有匹配索引值的行将从这张表中读取。 ref_or_null:该联接类型如同ref,但是添加了MySQL可以专门搜索包含NULL值的行。 index_merge:该联接类型表示使用了索引合并优化方法。 unique_subquery:该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。 index_subquery:该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr) range:只检索给定范围的行,使用一个索引来选择行。 index:该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。 一般来说，得保证查询至少达到range级别，最好能达到ref，否则就可能会出现性能问题。 key: Mysql实际使用的索引 Extra: Using filesort: Mysql需要额外的步骤排序，表示语句需要优化 Using temporary： 使用到临时表来存储查询结果，表示语句需要优化 SQL查询优化通过慢查询日志获取存在性能问题的SQL慢查询日志分析工具相关配置参数 12345678slow_query_log # 启动停止记录慢查日志，慢查询日志默认是没有开启的可以在配置文件中开启(on)slow_query_log_file # 指定慢查日志的存储路径及文件，日志存储和数据存储应该分开存储long_query_time # 指定记录慢查询日志SQL执行时间的阀值默认值为10秒通常,对于一个繁忙的系统来说,改为0.001秒(1毫秒)比较合适log_queries_not_using_indexes # 是否记录未使用索引的SQL 工具：pt-query-digest 1pt-query-digest --explain h=127.0.0.1,u=root,p=123456 slow-mysql.log pt-query-digest是用于分析mysql慢查询的一个工具，它可以分析binlog、General log、slowlog。可以把分析结果输出到文件中，也可以对SHOW PROCESSLIST或者通过tcpdump抓取的MySQL协议数据进行分析。分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间、次数、占比等，可以借助分析结果找出问题。 pt-query-digest工具的安装 因为pt-query-digest是包含在percona-tookit工具集中的，所以只要安装percona-tookit即可。percona-tookie链接：https://www.percona.com/doc/percona-toolkit/3.0/installation.html pt-query-digest工具的使用参考 https://www.cnblogs.com/luyucheng/p/6265873.html 实时获取存在性能问题的SQL直接通过表查询1234SELECT id,user,host,DB,command,time,state,infoFROM information_schema.processlistWHERE TIME&gt;=1 查询当前服务器执行超过1s的SQL，可以通过脚本周期性的来执行这条SQL，就能查出有问题的SQL。 通过pt-query-digst来分析1pt-query-digest --processlist h=host1 特定SQL的查询优化大表的数据修改大彪删除/更新100万或者更多1000万行记录，一次只删除/更新5000行记录，中间暂停几秒。 大表的结构在线修改添加一个新表（修改后的结构），老表数据导入新表，老表建立触发器，修改数据同步到新表， 老表加一个排它锁（重命名）， 新表重命名， 删除老表。 可以借助pt-online-schema-change工具来完成。 pt-oneline-schema-change 工具使用参考： https://blog.csdn.net/lovelichao12/article/details/73549939 优化not in和&lt;&gt;查询子查询改写为关联查询 12345select id,name from a where id not in (select id from b) 改写后： 12345select id,name from a left join b on a.id=b.idwhere b.id is null Mysql参考书籍： 《高性能mysql》 《MySQL 技术内幕：InnoDB 存储引擎》 《数据库索引设计与优化》 Nginx优化… 待完善…]]></content>
      <tags>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql数据库学习总结]]></title>
    <url>%2F2018%2F03%2F20%2FMysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[关系型数据库关系型数据库的三范式第一范式（1NF）: 每一列都是不可分割的原子数据项(基本类型列) 第二范式（2NF）： 要求实体的属性完全依赖于主关键字(无重复行) 第三范式（3NF）: 数据表不包含其它表已有的非主属性(无数据冗余) 关于数据库的规范设计，都会谈到是否符合三范式。但是考虑到数据库的性能优化，也不必都按照三范式来设计，可以做数据的适当冗余。如为了查询效率，在商品表，可以设置个img_url字段放图片的主图。 MySQL本质了解mysql逻辑架构 1.最上层是一些客户端和连接服务，包含本地sock通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 2.第二层架构主要完成大多的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化及部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如过程、函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等，最后生成相应的执行操作。如果是select语句，服务器还会查询内部的缓存。如果缓存空间足够大，这样在解决大量读操作的环境中能够很好的提升系统的性能。 3.存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。 4.数据存储层，主要是将数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互。 MySQL核心模块 • Server Initialization Module 命令行、配置文件解析、内存分配 • Connection Manager 协议监听和协议转发 • Thread Manager 新建线程处理请求 • Connection Thread 新建新的,或者从线程缓存中去取 • User Authentication Module 验证用户身份 • Access Control Module 访问控制 • Parser 接收请求,解析进入命令分发或者进入查询 • Command Dispatcher 解析器分发给命令分发器 • Query Cache Module 查询缓存检查(SELECT、DELETE、UPDATE) • Optimizer 查询优化器 • Table Manager 打开表,获取锁 • Table Modification Modules 表更新 • Table Maintenance Module 表维护 • Status Reporting Module 状态报告 • Abstracted Storage Engine Interface (Table Handler) 抽象引擎接口 • Storage Engine Implementations (MyISAM, InnoDB...) 存储引擎实现 • Logging Module 日志记录 • Replication Master Module 复制主模块 • Replication Slave Module 复制从模块 • Client/Server Protocol API 客户端、服务器协议 API • Low-Level Network I/O API 底层网络 I/O API • Core API 核心 API 存储引擎的区别和选择存储引擎是mysql提供的文件访问层的一个抽象接口来定制一种文件访问机制。 mysql的存储引擎包括:MyISAM、InnoDB、BDB、MEMORY、MERGE、EXAMPLE、NDBCluster、ARCHIVE、CSV、BLACKHOLE、FEDERATED等。 MyISAM:不支持事务,支持全文索引,表级锁；数据文件全量备份，可以直接拷贝数据文件进行备份；适合处理读频率远大于写频率的静态表。 InnoDB:支持事务,5.6以后支持全文索引,默认行级锁；数据文件两种形式(单一文件形式和多文件形式,以共享表空间与独占表空间存储)；适用于高并发读写。 MySQL InnoDB的存储文件参考：http://blog.csdn.net/chenjiayi_yun/article/details/45533909 MySQL插件NoSql 插件 HandlerSocket 中文全文索引插件 mysqlcft （mysql5.7内置有n-gram parser插件） InnoDB引擎中的Memcached插件 MySQL中的事务事务的ACID:• 原子性(Atomicity ) 全部执行或全部不执行 • 一致性( Consistency ) 事务前后数据都是一致性状态,约束等 • 隔离性或独立性( Isolation) 事务之间是独立的,和级别相关 • 持久性(Durabilily) 事务完成即持久化存储 MysSQL锁表类型1- 表级锁(MyISAM) 开销小,加锁快;不会出现死锁;锁定粒 度大,发生锁冲突的概率最高,并发度最低 可以通过检查table_locks_waited和table_locks_immediate状态变量来分析系统上的表锁定争夺： mysql> show status like 'table%'; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | Table_locks_immediate | 2979 | | Table_locks_waited | 0 | +-----------------------+-------+ 2 rows in set (0.00 sec)) 如果Table_locks_waited的值比较高，则说明存在着较严重的表级锁争用情况。 MySQL的表级锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。锁模式的兼容性如表20-1所示。 MySQL中的表锁兼容性 请求锁模式 是否兼容 当前锁模式 None 读锁 写锁 读锁 是 是 否 写锁 是 否 否 行级锁(InnoDB) 开销大,加锁慢;会出现死锁;锁定粒度最 小,发生锁冲突的概率最低,并发度也最高 可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况： mysql> show status like 'innodb_row_lock%'; +-------------------------------+-------+ | Variable_name | Value | +-------------------------------+-------+ | InnoDB_row_lock_current_waits | 0 | | InnoDB_row_lock_time | 0 | | InnoDB_row_lock_time_avg | 0 | | InnoDB_row_lock_time_max | 0 | | InnoDB_row_lock_waits | 0 | +-------------------------------+-------+ 5 rows in set (0.01 sec) 如果发现锁争用比较严重，如InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高，还可以通过设置InnoDB Monitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。 页面锁 开销和加锁时间界于表锁和行锁之间;会出现死锁;锁定 粒度界于表锁和行锁之间,并发度一般 使用悲观锁和乐观锁解决并发悲观锁在关系数据库管理系统里，悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 在DBMS中，悲观锁正是利用数据库本身提供的锁机制来实现的。 乐观锁乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。 参考： mysql悲观锁总结和实践 mysql乐观锁总结和实践 深入理解乐观锁与悲观锁 海量数据的分页优化方案 建立合适的索引 使用Redis缓存count,根据访问热度缓存靠后的分页数据 查找出limit的开始行id，然后用where拼接，如：where id&gt;*** limit 0,99 产品设计优化 MySQL的安装与配置MySQL源码安装下面在CentOS环境下安装、参考Oneinstack 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137# 下载mysql源码包wget -4 --tries=6 -c --no-check-certificate https://mirrors.tuna.tsinghua.edu.cn/mysql/downloads/MySQL-5.7/mysql-5.7.21.tar.gz# 进入软件目录pushd /opt/software/src# 添加mysql用户useradd -M -s /sbin/nologin mysql# 创建mysql的安装目录mkdir -p /usr/local/mysql# 创建mysql data目录mkdir -p /data/mysql# 更改mysql data目录权限chown mysql.mysql -R /data/mysqltar xzf mysql-5.7.21.tar.gzpushd mysql-5.7.21cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/data/mysql \ -DSYSCONFDIR=/etc \ -DWITH_INNOBASE_STORAGE_ENGINE=1 \ -DWITH_PARTITION_STORAGE_ENGINE=1 \ -DWITH_FEDERATED_STORAGE_ENGINE=1 \ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \ -DWITH_MYISAM_STORAGE_ENGINE=1 \ -DWITH_EMBEDDED_SERVER=1 \ -DENABLE_DTRACE=0 \ -DENABLED_LOCAL_INFILE=1 \ -DDEFAULT_CHARSET=utf8mb4 \ -DDEFAULT_COLLATION=utf8mb4_general_ci \ -DEXTRA_CHARSETS=all \ -DCMAKE_EXE_LINKER_FLAGS=&apos;-ljemalloc&apos;makemake installpopdrm -rf mysql-5.7.21cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqldsed -i &quot;s@^basedir=.*@basedir=/usr/local/mysql@&quot; /etc/init.d/mysqldsed -i &quot;s@^datadir=.*@datadir=/data/mysql@&quot; /etc/init.d/mysqldchmod +x /etc/init.d/mysqldchkconfig --add mysqldchkconfig mysqld on# 添加mysql配置 cat &gt; /etc/my.cnf &lt;&lt; EOF[client]port = 3306socket = /tmp/mysql.sockdefault-character-set = utf8mb4[mysql]prompt=&quot;MySQL [\\d]&gt; &quot;no-auto-rehash[mysqld]port = 3306socket = /tmp/mysql.sockbasedir = /usr/local/mysqldatadir = /data/mysqlpid-file = /data/mysql/mysql.piduser = mysqlbind-address = 0.0.0.0server-id = 1init-connect = &apos;SET NAMES utf8mb4&apos;character-set-server = utf8mb4skip-name-resolve#skip-networkingback_log = 300max_connections = 1000max_connect_errors = 6000open_files_limit = 65535table_open_cache = 128max_allowed_packet = 500Mbinlog_cache_size = 1Mmax_heap_table_size = 8Mtmp_table_size = 16Mread_buffer_size = 2Mread_rnd_buffer_size = 8Msort_buffer_size = 8Mjoin_buffer_size = 8Mkey_buffer_size = 4Mthread_cache_size = 8query_cache_type = 1query_cache_size = 8Mquery_cache_limit = 2Mft_min_word_len = 4log_bin = mysql-binbinlog_format = mixedexpire_logs_days = 7log_error = /dta/mysql/mysql-error.logslow_query_log = 1long_query_time = 1slow_query_log_file = /data/mysql/mysql-slow.logperformance_schema = 0explicit_defaults_for_timestamp#lower_case_table_names = 1skip-external-lockingdefault_storage_engine = InnoDB#default-storage-engine = MyISAMinnodb_file_per_table = 1innodb_open_files = 500innodb_buffer_pool_size = 64Minnodb_write_io_threads = 4innodb_read_io_threads = 4innodb_thread_concurrency = 0innodb_purge_threads = 1innodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 2Minnodb_log_file_size = 32Minnodb_log_files_in_group = 3innodb_max_dirty_pages_pct = 90innodb_lock_wait_timeout = 120bulk_insert_buffer_size = 8Mmyisam_sort_buffer_size = 8Mmyisam_max_sort_file_size = 10Gmyisam_repair_threads = 1interactive_timeout = 28800wait_timeout = 28800[mysqldump]quickmax_allowed_packet = 500M[myisamchk]key_buffer_size = 8Msort_buffer_size = 8Mread_buffer = 4Mwrite_buffer = 4MEOF# 数据库初始化/usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysqlchown mysql.mysql -R /data/mysqlservice mysqld start# 设置环境变量echo &quot;export PATH=/usr/local/mysql/bin:\$PATH&quot; &gt;&gt; /etc/profile[ -z &quot;$(grep ^&apos;export PATH=&apos; /etc/profile)&quot; ] &amp;&amp; echo &quot;export PATH=/usr/local/mysql/bin:\$PATH&quot; &gt;&gt; /etc/profile[ -n &quot;$(grep ^&apos;export PATH=&apos; /etc/profile)&quot; -a -z &quot;$(grep /usr/local/mysql /etc/profile)&quot; ] &amp;&amp; sed -i &quot;s@^export PATH=\(.*\)@export PATH=/usr/local/mysql/bin:\1@&quot; /etc/profile# 设置密码/usr/local/mysql/bin/mysql -e &quot;grant all privileges on *.* to root@&apos;127.0.0.1&apos; identified by &quot;123456&quot; with grant option;&quot;/usr/local/mysql/bin/mysql -e &quot;grant all privileges on *.* to root@&apos;localhost&apos; identified by &quot;123456&quot; with grant option;&quot;# 添加动态链接库echo &quot;/usr/local/mysql/lib&quot; &gt; /etc/ld.so.conf.d/mysql.confldconfigservice mysqld restart MySQL源码目录 • BUILD 编译脚本 • client 命令行工具代码(mysql,mysqladmin) • cmd-line-utils 增强命令行的第三方库 (libedit 如 readline). • dbug 调试库 • libevent 由于 5.6 支持 某个插件的库 • plugin 插件所在的库 • libmysql MySQL 的库,其他客户端,经如C/PHP 访问MySQL需 要引用这个目录的库 • mysys 核心可移植性或者工具API • regex 正则表达式库 • scripts 脚本库,如 mysqld_safe 所在 • sql MySQL 的核心所在,用C++所写 • sql-common 客户端、服务器能用代码 • strings 字符串库 • storage 存储引擎所在的库 • vio 底层网络I/O操作库 • zlib库 数据库配置优化基础配置连接数配置通过show variables like &#39;%conn%&#39;;查看配置 max_connections 设置整个服务器最大session连接数 max_user_connections 每个用户的session连接个数,值为0时表示每个用户的连接数不受限制 网络配置skip-name-resolve：禁止掉DNS的查询 解释：mysql会在用户登录过程中对客户端IP进行DNS反查，不管你是使用IP登录还是域名登录，这个反查的过程都是在的。所以如果你的mysql所在的服务器的DNS有问题或者质量不好，那么就有可能造成127.0.0.1登录很快，用域名或者IP登录数据库很慢的DNS解析问题。 数据库加这个参数速度会变快skip-name-resolve，但是也有注意点，mysql.user 表里面的host不要用localhost之类的，要用127.0.0.1，不然连自己都连不上数据库，会报错。 缓存配置查询缓存查询缓存的作用就是当查询接收到一个和之前同样的查询，服务器将会从查询缓存种检索结果，而不是再次分析和执行上次的查询。这样就大大提高了性能，节省时间。当查询很大、更新很少的情况下可以使用查询缓存。 查看缓存设置1show variables like &apos;%query_cache%&apos;; 输出如下： +------------------------------+---------+ | Variable_name | Value | +------------------------------+---------+ | have_query_cache | YES | | query_cache_limit | 1048576 | | query_cache_min_res_unit | 4096 | | query_cache_size | 1048576 | | query_cache_type | OFF | | query_cache_wlock_invalidate | OFF | +------------------------------+---------+ 查看缓存的状态使用show status like &#39;%Qcache%&#39;; 输出结果： +-------------------------+---------+ | Variable_name | Value | +-------------------------+---------+ | Qcache_free_blocks | 1 | | Qcache_free_memory | 1031832 | | Qcache_hits | 0 | | Qcache_inserts | 0 | | Qcache_lowmem_prunes | 0 | | Qcache_not_cached | 4 | | Qcache_queries_in_cache | 0 | | Qcache_total_blocks | 1 | +-------------------------+---------+ 参考：mysql查询缓存打开、设置、参数查询、性能变量意思 日志配置通用查询日志通用查询日志：记录建立的客户端连接和执行的语句 1). 查看通用查询日志配置1show variables like &apos;%general%&apos;; 输出结果： +------------------+------------------------------+ | Variable_name | Value | +------------------+------------------------------+ | general_log | OFF | | general_log_file | /data/mysql/xxxxxx.log | +------------------+------------------------------+ 通用查询日志默认是关闭的。 2). 查看当前日志输出的格式 1MySQL [(none)]&gt; show variables like &apos;%log_output%&apos;; 输出结果： +---------------+-------+ | Variable_name | Value | +---------------+-------+ | log_output | FILE | +---------------+-------+ 1 row in set (0.01 sec) 日志格式可以是FILE（存储在数数据库的数据文件中的hostname.log），也可以是TABLE（存储在数据库中的mysql.general_log） 3) 开启通用查询日志的方式 通过set命令设置，只对当前mysql生效，重启失效 12set global general_log=on;set global log_output=&apos;TABLE&apos;; # 值为“FILE”、“TABLE“或者“FILE,TABLE” 通过配置文件my.cnf配置 12general_log=1 # 为1表示开启通用日志查询，值为0表示关闭通用日志查询log_output=FILE,TABLE # 设置通用日志的输出格式为文件和表 慢查询日志MySQL的慢查询日志是MySQL提供的一种日志记录，用来记录在MySQL中响应时间超过阈值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中（日志可以写入文件或者数据库表，如果对性能要求高的话，建议写文件）。默认情况下，MySQL数据库是不开启慢查询日志的，long_query_time的默认值为10（即10秒，通常设置为1秒），即运行10秒以上的语句是慢查询语句。 1) 查看是否开启慢查询日志 1show variables like &apos;%quer%&apos;; 输出结果中 slow_query_log值为ON时表示开启 slow_query_log_file 的值是记录的慢查询日志到文件中（注意：默认名为主机名.log，慢查询日志是否写入指定文件中，需要指定慢查询的输出日志格式为文件，相关命令为：show variables like ‘%log_output%’；去查看输出的格式。当设置为TABLE时，慢查询日志输出至mysql.slow_log中） 2) 在配置文件中配置慢查询 123slow_query_log = 1long_query_time = 1slow_query_log_file = /data/mysql/mysql-slow.log 3) 如何制造慢查询，看慢查询设置是否有效 1&gt; select sleep(5) 二进制配置主要作数据库的恢复和同步使用 123log_bin = mysql-binbinlog_format = mixedexpire_logs_days = 7 错误日志1log_error = /data/mysql/mysql-error.log]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让github上fork的项目同步原项目]]></title>
    <url>%2F2018%2F02%2F24%2F%E8%AE%A9github%E4%B8%8Afork%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%90%8C%E6%AD%A5%E5%8E%9F%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[1234567891011121314## 先clone到本地仓库git clone https://github.com/yunshu2009/think.git## 保持和远程仓库同步git remote add upstream https://github.com/top-think/think.git## 拉取远程仓库最新代码git fetch upstream## 合并到本地仓库git merge upstream/master## 及时更新最新改动git pull --rebase]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SSR科学上网]]></title>
    <url>%2F2018%2F02%2F19%2F%E4%BD%BF%E7%94%A8SSR%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[使用一键安装脚本安装shadowsocksR参考：https://shadowsocks.be/9.html 123wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.shchmod +x shadowsocksR.sh./shadowsocksR.sh 在CentOS 7上安装BBR加速参考： 部署方法：https://www.vultr.com/docs/how-to-deploy-google-bbr-on-centos-7) 一键安装脚本：https://github.com/teddysun/across/raw/master/bbr.sh 检测linux vps是xen openvz还是kvm的方法https://blog.slogra.com/post-632.html SSR客户端MAC客户端： https://github.com/qinyuhang/ShadowsocksX-NG-R/releases Linux客户端：https://raw.githubusercontent.com/the0demiurge/CharlesScripts/master/charles/bin/ssr Windows客户端：https://github.com/shadowsocksr-backup/shadowsocksr-csharp/releases IOS客户端：Potatso Lite、Potatso、shadowrocket (需要使用美区apple id下载软件) SSR多用户配置配置文件如下 123456789101112131415161718192021&#123;&quot;server&quot;:&quot;0.0.0.0&quot;,&quot;server_ipv6&quot;: &quot;[::]&quot;,&quot;local_address&quot;:&quot;127.0.0.1&quot;,&quot;local_port&quot;:1080,&quot;port_password&quot;:&#123; &quot;8989&quot;:&quot;password1&quot;,//着里输入想要的端口和密码 &quot;8990&quot;:&quot;password2&quot;， &quot;8991&quot;:&quot;password3&quot;&#125;,&quot;timeout&quot;:300,&quot;method&quot;:&quot;aes-256-cfb&quot;,//加密方式可以修改也可以不修改本人用chacha20&quot;protocol&quot;: &quot;origin&quot;,//协议也是可以修改了本人用auth_sha1&quot;protocol_param&quot;: &quot;&quot;,&quot;obfs&quot;: &quot;plain&quot;,//这里很重要,免流的请注意必须修改,本人用http_simple&quot;obfs_param&quot;: &quot;&quot;,&quot;redirect&quot;: &quot;&quot;,&quot;dns_ipv6&quot;: false,&quot;fast_open&quot;: false,&quot;workers&quot;: 1&#125; 然后修改防火墙，添加上面添加的端口即可，重启防火墙和SSR即可。 参考链接：https://www.cnblogs.com/gne-hwz/p/6662000.html 其他参考 http://blog.sina.com.cn/s/blog_4891cbc50102x5lw.html SSR共享如果你感觉梯子搭建麻烦，也可联系我共享SSR ~~]]></content>
      <tags>
        <tag>科学上网</tag>
      </tags>
  </entry>
</search>
