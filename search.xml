<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用Beautifulsoup抓取91ud小程序]]></title>
    <url>%2F2018%2F08%2F10%2F%E4%BD%BF%E7%94%A8Beautifulsoup%E6%8A%93%E5%8F%9691ud%E5%B0%8F%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[环境部署/依赖包安装安装virtualenv使用virtualenv为每个项目建立不同的/独立的Python环境，减少软件冲突。 安装方法 1pip install virtualenv 安装virtualenvwrappervirtualenvwrapper 是一个建立在 virtualenv 上的工具，通过它可以方便的创建/激活/管理/销毁虚拟环境。 安装方法： 1pip install virtualenvwrapper 新建虚拟环境/安装软件12345678910# 新建虚拟环境mkvirtualenv --python=/usr/local/bin/python3 91ud-spider# 切换虚拟环境workon 91ud-spider# 安装依赖包pip install -i https://pypi.douban.com/simple requestspip install -i https://pypi.douban.com/simple mysqlclientpip install -i https://pypi.douban.com/simple beautifulsoup4 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156# -*- coding: utf-8 -*-__author__ = &apos;yunshu&apos;import requestsimport osimport jsonimport timeimport hashlibimport randomimport MySQLdbfrom bs4 import BeautifulSoupfrom urllib import parse&apos;&apos;&apos;使用Beautifulsoup抓取91ud小程序Beautifulsoup文档参考：http://www.jb51.net/article/65287.htmpython版本：3.6&apos;&apos;&apos;headers = &#123; &apos;User-Agent&apos;:&apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&apos;&#125;conn = MySQLdb.connect(host=&apos;localhost&apos;, user=&apos;root&apos;, passwd=&apos;123456&apos;, db=&apos;spiders&apos;, charset=&apos;utf8&apos;)cursor = conn.cursor()def spider(minpage=1, maxpage=2): content = [] index = minpage*48 for page in range(minpage, maxpage): if page == 1: request_url = &apos;http://www.91ud.com/app/&apos; else: request_url = &apos;http://www.91ud.com/app/%d&apos; % page r = requests.get(request_url, headers=headers) if r.status_code == 200: soup = BeautifulSoup(r.text, &apos;lxml&apos;) items = soup.find_all(&apos;li&apos;, attrs=&#123;&apos;class&apos;:&apos;item&apos;&#125;) for item in items: index = index + 1 detail_url = item.find(&apos;a&apos;, attrs=&#123;&apos;class&apos;:&apos;avatar&apos;&#125;).get(&apos;href&apos;) detail_url = parse.urljoin(r.url, detail_url) detail = get_detail(detail_url) detail[&apos;order&apos;] = index insert_db(detail) content.append(detail) else: print(r.status_code) # r.raise_for_status() print(&apos;fetch %s&apos; % request_url) time.sleep(random.randint(1,3)) conn.close() with open(&apos;q1ud.json&apos;, &apos;w&apos;, encoding=&apos;utf-8&apos;) as fp: json.dump(content, fp=fp, indent=4, ensure_ascii=False)def get_detail(url): detail = &#123;&#125; r = requests.get(url, headers=headers) if r.status_code == 200: soup = BeautifulSoup(r.text, &apos;lxml&apos;) title = soup.find(&apos;h1&apos;).get_text() tag_list = [] avatar = soup.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;:&apos;intro&apos;&#125;).find(&apos;img&apos;).get(&apos;src&apos;) tags = soup.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;:&apos;tags&apos;&#125;).find_all(&apos;a&apos;) qrcode = soup.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;:&apos;qrcode&apos;&#125;).find(&apos;img&apos;).get(&apos;src&apos;) category = soup.find(&apos;ul&apos;, attrs=&#123;&apos;class&apos;:&apos;info&apos;&#125;).find(&apos;a&apos;).get(&apos;href&apos;).strip(&apos;/&apos;) os_infos = soup.find(&apos;ul&apos;, attrs=&#123;&apos;class&apos;:&apos;info&apos;&#125;).find_all(&apos;strong&apos;) # 待过滤处理html，去掉超链接等 desc = soup.find(&apos;div&apos;, attrs=&#123;&apos;class&apos;:&apos;description&apos;&#125;).find(&apos;p&apos;).prettify() os_info = os_infos[3].get_text() create_time = os_infos[1].get_text() for tag in tags: tag_list.append(tag.get_text()) detail[&apos;title&apos;] = title detail[&apos;avatar&apos;] = avatar detail[&apos;tag_list&apos;] = &apos;,&apos;.join(tag_list) detail[&apos;qrcode&apos;] = qrcode detail[&apos;category&apos;] = category detail[&apos;create_time&apos;] = create_time detail[&apos;os_info&apos;] = os_info detail[&apos;desc&apos;] = desc detail[&apos;url&apos;] = r.url detail[&apos;url_object_id&apos;] = get_md5(url) path = get_save_path(&apos;images&apos;) if download_image(detail[&apos;qrcode&apos;], path): detail[&apos;local_image&apos;] = path + &apos;/&apos; + qrcode.split(&apos;/&apos;)[-2] + &apos;.jpg&apos; else: detail[&apos;local_image&apos;] = &apos;&apos; path = get_save_path(&apos;avatar&apos;) if download_image(detail[&apos;avatar&apos;], path): detail[&apos;local_avatar&apos;] = path + &apos;/&apos; + avatar.split(&apos;/&apos;)[-2] + &apos;.jpg&apos; else: detail[&apos;local_avatar&apos;] = &apos;&apos; else: print(&apos;fetch url:%s error&apos; % url) return detaildef get_save_path(path): subdir = (str(random.randint(1, 20))) if not os.path.exists(path + &apos;/&apos; + subdir): os.makedirs(path + &apos;/&apos; + subdir) return path + &apos;/&apos; + subdirdef insert_db(detail): sql = &quot;insert into 91ud(title,avatar,local_image,local_avatar,tag_list,qrcode,category,os_info, `desc`, create_at, `order`,`url`,`url_object_id`) values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s, %s,%s) ON DUPLICATE KEY UPDATE title=%s&quot; vals = (detail[&apos;title&apos;], detail[&apos;avatar&apos;], detail[&apos;local_image&apos;], detail[&apos;local_avatar&apos;], detail[&apos;tag_list&apos;], detail[&apos;qrcode&apos;], detail[&apos;category&apos;], detail[&apos;os_info&apos;], detail[&apos;desc&apos;], detail[&apos;create_time&apos;], detail[&apos;order&apos;],detail[&apos;url&apos;], detail[&apos;url_object_id&apos;],detail[&apos;title&apos;]) cursor.execute(sql, vals) conn.commit()def download_image(url, path): print(&quot;download image %s&quot; % url) get_file_name = lambda url: os.path.join(path, url.split(&apos;/&apos;)[-2] + &apos;.jpg&apos;) headers[&apos;Referer&apos;] = url response = requests.get(url, headers=headers) if response.status_code == 200: file_name = get_file_name(url) with open(file_name, &apos;wb&apos;) as f: f.write(response.content) return True else: print(&apos;fetch image %s error&apos; % url) return Falsedef get_md5(url): # 如果是unicode字符串，则进行utf-8编码 if isinstance(url, str): url = url.encode(&apos;utf-8&apos;) m = hashlib.md5() m.update(url) return m.hexdigest()if __name__ == &apos;__main__&apos;: spider(1, 2) 代码链接：https://github.com/pythondev-cn/pythonspiders/blob/master/91ud/91ud.py]]></content>
  </entry>
  <entry>
    <title><![CDATA[《高性能MySQL》读书笔记]]></title>
    <url>%2F2018%2F08%2F01%2F%E3%80%8A%E9%AB%98%E6%80%A7%E8%83%BDMySQL%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Schema与数据类型优化选择的优化的数据类型 一般情况下，应该尽量使用可以正确存储数据的最小数据类型。更小的数据类型通常更快，因为他们占用更少的磁盘、内存和CPU缓存，并且处理时需要的CPU周期更少。 使用简单的数据类型。例如，整型比字符串操作代价更低，因为字符串集和校对规则（排序规则）使字符比较比整形比较更复杂。另外，应该使用应该使用mysql的内建类型而不是字符串存储日期和时间，应该使用整形存储IP地址。 尽量避免NULL值。使用NULL的列会使用更多的存储空间，在MySQL里需要特殊处理。当可为NULL的列被索引时，每个索引需要一个额外的字节，在MyISAM里甚至可能导致固定大小的所有（例如只有一个整形列的索引）变成可大可小的索引。通过把可为NULL的列改为NOT NULL带来的性能提升比较小，如果不确定这回导致性能瓶颈问题不必要首先修改。如果计划在列上建索引，就尽量避免设计成可为NULL的列。 MySQL为了兼容性支持了很多别名，例如INTEGER、BOOL以及NUMERIC, 他们只是别名。这些别名不会影响性能。如果建表时采用数据类型的别名，用SHOW CREATE TABLE可以发现报告的是基本数据类型，而不是别名。 整型类型 整型类型有这几种：TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT。分别使用8，16， 24， 32， 64位存储空间。他们可以存储的范围从-2(n-1) ~ 2(n-1)-1 （-2的n-1次方到2的n-1次方-1），其中N是存储空间的位数。 整型类型有可选的UNSIGNED属性，表示不允许负值， 这大致可以使得正数的上限提高一倍。例如TINYINT UNSIGNED可以存储的范围是0~255。 MySQL可以为整数类型指定宽度，例如INT(11)，对大多数应用来说这是没有意义的：它不会限制值的合法范围，只是规定了MySQL的一些交互工具（例如MySQL命令行客户端）用来显示字符的个数。对于存储和计算来说INT(11)和INT(20)是相同的。 实数类型 FLOAT和DOUBLE类型致辞使用标准的浮点预算进行近似计算。 DECIMAL类型用于存储精确的小数。在MySQL 5.0以及更高版本中，DECIMAL类型支持精度计算。因为CPU不支持对DECIMAL的直接计算，所以在MySQL 5.0以及更高的版本中，MySQL服务器自身实现了DECIMAL的高精度计算。相对而言，CPU直接支持原生浮点计算，所以浮点运算明显更快。 对于DECIMAL列，可以指定小数点前后所允许的最大位数。MySQL 5.0和更高版本将数字打包保存到一个二进制字符串中（每4个字节存9个数字）。例：DECIMAL(18，9）将存储9个字节（其中小数点占用1个字节）。 浮点类型在存储同样范围的值时，通常比DECIMAL使用更少的存储空间。FlOAT使用4个字节存储。DOUBLE占用8个字节，相比FLOAT有更高的精度和更大的范围。MySQL使用DOUBLE作为内部浮点计算的类型。 因为需要额外的空间和计算开销，所以应该尽量对小数进行精确计算时才使用DECIMAL—例如存储财务数据。一个技巧是用BIGINT存储DECIMAL数值（只需要将数值乘以相应的倍数即可），避免浮点存储计算不精确和DECIMAL精确计算代价高的问题。 字符串类型 VARCHAR 可以存储可变长字符串，是最常见的字符串数据类型。它比定长类型更节省空间，因为它使用必要的空间。有一种情况例外，如果MySQL表使用ROW_FORMAT=FIXED创建的话，每一行都会使用定长存储，这会很浪费空间。 VARCHAR需要使用1个或者2个额外的字节记录字符串的长度；如果列的最大长度小于或者等于255个字节，则只使用1个字节，否则使用2个字节。 CHARCHAR类型是定长的。当存储CHAR值时，MySQL会删除所有的末尾空格。CHAR值适合存储定长的字段，或者说所有值都接近同一个长度（这种情况下，使用CHAR值存储不容易产生碎片）。 BINARY和VARBINARY这两种类型存储的是二进制字符串。二进制字符串使用字节码存储。BINARY采用\0(零字节）来填充使得长度达到指定的长度。当需要存储二进制数据，并且希望MySQL使用字节码而不是字符进行比较时，可以使用二进制类型。 BLOB和TEXT类型BLOB和TEXT都是为存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储。BLOB类型包含了TINYBLOB、SMALLBLOB、BLOB、MEDIUMBLOB、LONGBLOB。BLOB是SMALLBLOB的同义词，TEXT是SMALLTEXT的同义词。 BLOB类型存储的是二进制数据，没有排序规则或者数据集，而TEXT类型有字符集和排序规则。 枚举类型枚举类型可以把一些不重复的字符串存储在一个预定义的集合中。MySQL在内部将每个值在列表中的位置保存为整数，在表的.frm文件中保存“数字 - 字符串”映射关系的“查找表”。另外，枚举字段排序是安装内存存储的整数进行排序的。 缺点：字符串列表时固定的，添加或者删除元素，需要ALTER TABLE。所以未来会改变字符串的字段，使用枚举并不合适。 日期和时间类型MySQL提供两种相似的时间类型：DATETIME和TIMESTAMP，两种时间类型支持存储的最小粒度为秒（MariaDB支持微妙级别的时间类型）。 DATETIME这个类型能保存大范围的值，从1001年到9999年。存储的时间与时区无关，占用8个字节的存储空间。 TIMESTAMP这个类型保存的范围从1970年到2038年，占用4个字节的存储空间。TIMESTAMP显示的值依赖于失去。MySQL服务器、操作系统，以及客户端连接都有时区设置。 推荐尽量使用TIMESTAMP类型，因为它比DATETIME的空间利用率高。此外不推荐使用整型存储时间，不方便处理。 如果要存储微妙级别的时间，可以使用BIGINT存储微妙级别的时间戳，或者使用DOUBLE类型存储秒之后的小数部分。 选择标识符 为标识列选择数据类型时，应该选择跟关联表中的对应列一样的类型。类型之间要精确匹配，包括想UNSIGNED这样的属性。 应当避免使用字符串类型作为标识符，因为他们很消耗空间并且通常比数字慢。推荐使用整数作为标识符。 一些其它建议如存储ipv4地址，使用UNSIGNED INT存储，它比使用CHAR(15)有更高的空间效率。使用inet_aton可将把ip转为无符号整型，使用inet_ntoa可把整型的ip转为电地址。 MySQL schema设计的一些指导原则 一个表不要有太多的列 减少表关联 适度使用NULL值，减少应用复杂程度，避免引入奇怪的BUG。 创建高性能的索引索引的类型B-Tree 索引大家一般说索引的时候， 如果没有特别指明类型， 多半说的是B-Tree索引，它使用B-Tree数据结构来存储数据。 B-Tree通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同。 B-Tree索引使用与全键值、键值范围或者键值前缀前缀查找。其中键前缀查找只适用于根据最左前缀的查找。对如下类型的查询有效。 全值匹配 全值匹配值的是和索引中的所有列进行匹配。 匹配最左前缀 查询只使用到索引的第一列。 匹配列前缀 只匹配某列的值的开头部分。 如使用like查询索引匹配第一列的前面部分字符。 匹配范围值 使用B-Tree索引的限制 如果不是按照索引的最左列开始查找，则无法使用索引。 （查询必须包含最左列，并且不能查询左列以某字母结尾的行，才能使用到索引） 哈希索引哈希索引（hash index）基于哈希表实现，只有精确匹配所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算出一个哈希码（hash code）,哈希码是一个较小的值，并且在不同的键值的行计算出来的哈希码也不一样。哈希索引将所有的哈希码存储在所有中，同时在哈希表中保存指向每个数据行的指针。 哈希索引的限制 哈希索引数据不是按照索引值顺序存储的，无法用于排序。 哈希索引值只支持等值比较查询。 可以使用SRC32()做为哈希函数存储哈希值，但是如果数据量很大，会出现哈希冲突的情况。 不要使用SHA1()和MD5()作为哈希函数。这两个函数计算出来的哈希值是一个非常长的字符串，会浪费大量的空间，比较时也比较慢。 要解决冲突问题，必须在where条件中带入哈希值和对应的列值。 select world,crc from words where cc=CRC32(&#39;gnu&#39;) and word=&#39;gnu&#39; 还可以使用FNV64()函数作为哈希函数解决冲突。FNV64()哈希值为64位，速度快，且冲突比CRC32()要少的多。 全文索引全文索引必须要使用关键词MATCH和AGAINST，而不是使用WHERE进行搜索。]]></content>
  </entry>
  <entry>
    <title><![CDATA[thinkphp5 “$this->redirect()” 到底经历了啥]]></title>
    <url>%2F2018%2F04%2F07%2Fthinkphp5-source-reading%2F</url>
    <content type="text"><![CDATA[redirect方法，可以在自定义的控制器实现跳转的功能。看thinkphp 5.1源码发现它是在在jump trait中定义的一个方法。 Controller.php 12345678910111213141516171819202122232425...use traits\controller\Jump;class Controller&#123; use Jump; /** * 视图类实例 * @var \think\View */ protected $view; /** * Request实例 * @var \think\Request */ protected $request;...&#125; jump.php 可以看到它抛出一个异常 12345678910111213141516171819202122232425262728293031323334353637&lt;?php...namespace traits\controller;use think\Container;use think\exception\HttpResponseException;use think\Response;use think\response\Redirect;trait Jump&#123; . . . protected function redirect($url, $params = [], $code = 302, $with = []) &#123; $response = new Redirect($url); if (is_integer($params)) &#123; $code = $params; $params = []; &#125; $response-&gt;code($code)-&gt;params($params)-&gt;with($with); throw new HttpResponseException($response); &#125; . . . &#125; 查看HttpResponseException可以发现它是Excepton的子类 HttpResponseException.php 1234567891011121314151617181920&lt;?phpnamespace think\exception;use think\Response;class HttpResponseException extends \RuntimeException&#123; protected $response; public function __construct(Response $response) &#123; $this-&gt;response = $response; &#125; public function getResponse() &#123; return $this-&gt;response; &#125;&#125; RuntimeException是SPL中的类,它继承Exception12class RuntimeException extends Exception &#123;&#125; 到此我们知道了redirect()方法其实是抛出一个异常，那它是在哪里调用然后输出（跳转）呢？ 从入口文件index.php开始。发现先加载base.php，然后执行App类的run方法。然后调用返回对象的send方法 12345678910&lt;?phpnamespace think;// 加载基础文件require __DIR__ . &apos;/../thinkphp/base.php&apos;;// 支持事先使用静态方法设置Request对象和Config对象// 执行应用并响应Container::get(&apos;app&apos;)-&gt;run()-&gt;send(); App类,发现它catch了一个HttpResponseException，返回Redirect类型的Response 对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115&lt;?phpnamespace think;use think\exception\ClassNotFoundException;use think\exception\HttpResponseException;use think\route\Dispatch;/** * App 应用管理 */class App implements \ArrayAccess&#123; const VERSION = &apos;5.1.5&apos;; . . . // 执行应用程序 public function run() &#123; // 初始化应用 $this-&gt;initialize(); try &#123; if ($this-&gt;bind) &#123; // 模块/控制器绑定 $this-&gt;route-&gt;bind($this-&gt;bind); &#125; elseif ($this-&gt;config(&apos;app.auto_bind_module&apos;)) &#123; // 入口自动绑定 $name = pathinfo($this-&gt;request-&gt;baseFile(), PATHINFO_FILENAME); if ($name &amp;&amp; &apos;index&apos; != $name &amp;&amp; is_dir($this-&gt;appPath . $name)) &#123; $this-&gt;route-&gt;bind($name); &#125; &#125; // 读取默认语言 $this-&gt;lang-&gt;range($this-&gt;config(&apos;app.default_lang&apos;)); if ($this-&gt;config(&apos;app.lang_switch_on&apos;)) &#123; // 开启多语言机制 检测当前语言 $this-&gt;lang-&gt;detect(); &#125; $this-&gt;request-&gt;langset($this-&gt;lang-&gt;range()); // 加载系统语言包 $this-&gt;lang-&gt;load([ $this-&gt;thinkPath . &apos;lang/&apos; . $this-&gt;request-&gt;langset() . &apos;.php&apos;, $this-&gt;appPath . &apos;lang/&apos; . $this-&gt;request-&gt;langset() . &apos;.php&apos;, ]); // 监听app_dispatch $this-&gt;hook-&gt;listen(&apos;app_dispatch&apos;); // 获取应用调度信息 $dispatch = $this-&gt;dispatch; if (empty($dispatch)) &#123; // 进行URL路由检测 $dispatch = $this-&gt;routeCheck(); &#125; // 记录当前调度信息 $this-&gt;request-&gt;dispatch($dispatch); // 记录路由和请求信息 if ($this-&gt;debug) &#123; $this-&gt;log(&apos;[ ROUTE ] &apos; . var_export($this-&gt;request-&gt;routeInfo(), true)); $this-&gt;log(&apos;[ HEADER ] &apos; . var_export($this-&gt;request-&gt;header(), true)); $this-&gt;log(&apos;[ PARAM ] &apos; . var_export($this-&gt;request-&gt;param(), true)); &#125; // 监听app_begin $this-&gt;hook-&gt;listen(&apos;app_begin&apos;); // 请求缓存检查 $this-&gt;request-&gt;cache( $this-&gt;config(&apos;app.request_cache&apos;), $this-&gt;config(&apos;app.request_cache_expire&apos;), $this-&gt;config(&apos;app.request_cache_except&apos;) ); // 执行调度 $data = $dispatch-&gt;run(); &#125; catch (HttpResponseException $exception) &#123; $data = $exception-&gt;getResponse(); &#125; $this-&gt;middlewareDispatcher-&gt;add(function (Request $request, $next) use ($data) &#123; // 输出数据到客户端 if ($data instanceof Response) &#123; $response = $data; &#125; elseif (!is_null($data)) &#123; // 默认自动识别响应输出类型 $isAjax = $request-&gt;isAjax(); $type = $isAjax ? $this-&gt;config(&apos;app.default_ajax_return&apos;) : $this-&gt;config(&apos;app.default_return_type&apos;); $response = Response::create($data, $type); &#125; else &#123; $response = Response::create(); &#125; return $response; &#125;); $response = $this-&gt;middlewareDispatcher-&gt;dispatch($this-&gt;request); // 监听app_end $this-&gt;hook-&gt;listen(&apos;app_end&apos;, $response); return $response; &#125; . . .&#125; 继续看Redirect类父类Response的send方法。它设置了header头等 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?php namespace think;use think\response\Redirect as RedirectResponse;class Response&#123; . . . /** * 发送数据到客户端 * @access public * @return void * @throws \InvalidArgumentException */ public function send() &#123; // 监听response_send Container::get(&apos;hook&apos;)-&gt;listen(&apos;response_send&apos;, $this); // 处理输出数据 $data = $this-&gt;getContent(); // Trace调试注入 if (Container::get(&apos;env&apos;)-&gt;get(&apos;app_trace&apos;, Container::get(&apos;app&apos;)-&gt;config(&apos;app.app_trace&apos;))) &#123; Container::get(&apos;debug&apos;)-&gt;inject($this, $data); &#125; if (200 == $this-&gt;code &amp;&amp; $this-&gt;allowCache) &#123; $cache = Container::get(&apos;request&apos;)-&gt;getCache(); if ($cache) &#123; $this-&gt;header[&apos;Cache-Control&apos;] = &apos;max-age=&apos; . $cache[1] . &apos;,must-revalidate&apos;; $this-&gt;header[&apos;Last-Modified&apos;] = gmdate(&apos;D, d M Y H:i:s&apos;) . &apos; GMT&apos;; $this-&gt;header[&apos;Expires&apos;] = gmdate(&apos;D, d M Y H:i:s&apos;, $_SERVER[&apos;REQUEST_TIME&apos;] + $cache[1]) . &apos; GMT&apos;; Container::get(&apos;cache&apos;)-&gt;tag($cache[2])-&gt;set($cache[0], [$data, $this-&gt;header], $cache[1]); &#125; &#125; if (!headers_sent() &amp;&amp; !empty($this-&gt;header)) &#123; // 发送状态码 http_response_code($this-&gt;code); // 发送头部信息 foreach ($this-&gt;header as $name =&gt; $val) &#123; header($name . (!is_null($val) ? &apos;:&apos; . $val : &apos;&apos;)); &#125; &#125; $this-&gt;sendData($data); if (function_exists(&apos;fastcgi_finish_request&apos;)) &#123; // 提高页面响应 fastcgi_finish_request(); &#125; // 监听response_end Container::get(&apos;hook&apos;)-&gt;listen(&apos;response_end&apos;, $this); // 清空当次请求有效的数据 if (!($this instanceof RedirectResponse)) &#123; Container::get(&apos;session&apos;)-&gt;flush(); &#125; &#125; . . .&#125; 最后应用终止时会执行shutdown处理方法。它在Error.php已经注册了shutdown方法为Error类的appShutdown方法 1234567891011121314151617&lt;?php class Error &#123; . . . public static function register() &#123; error_reporting(E_ALL); set_error_handler([__CLASS__, &apos;appError&apos;]); set_exception_handler([__CLASS__, &apos;appException&apos;]); register_shutdown_function([__CLASS__, &apos;appShutdown&apos;]); &#125; . . .&#125; appShutdown方法 123456789101112public static function appShutdown()&#123; if (!is_null($error = error_get_last()) &amp;&amp; self::isFatal($error[&apos;type&apos;])) &#123; // 将错误信息托管至think\ErrorException $exception = new ErrorException($error[&apos;type&apos;], $error[&apos;message&apos;], $error[&apos;file&apos;], $error[&apos;line&apos;]); self::appException($exception); &#125; // 写入日志 Container::get(&apos;log&apos;)-&gt;save();&#125; OK. 另：thinkphp 5.0源码阅读参考：https://www.kancloud.cn/zmwtp/tp5/155311]]></content>
      <tags>
        <tag>php,thankphp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库扩展]]></title>
    <url>%2F2018%2F04%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[复制和分离主从复制复制原理: master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； slave将master的binary log events拷贝到它的中继日志(relay log)； slave重做中继日志中的事件。 复制过程对于主服务器的影响非常有限。当存在多个从服务器同时从一个主武器进行复制的时候，主服务器的磁盘压力会有不同程度额增长，可以采用多级复制策略解决。 读写分离对于查询操作比较密集的站点，将读操作分配给从服务器，写操作分配给主服务器。 mysqlroute数据库反向代理mysqlroute工作在应用程序和mysql服务器之间，负责所有请求和响应数据的转发。mysqlroute会将应用的读请求分配到主服务器上，将写请求分配到从服务器上，最后将结果返回给应用，在开始时只需要对mysqlroute做一些配置即可。 也可以使用Mycat数据库中间件 垂直分区当数据库写操作频繁的站点来说，可以采用垂直分区来解决。 将不同类型的数据库转移到独立的数据库服务器上，然后又可以对分出去的数据库做主从复制来实现读写分离。 水平分区当通过垂直分区后，数据库的主服务器再次无法承受写操作压力时，我们可以将同一数据表中的记录通过特定的算法进行分离，分别保存到不同的数据库表中，从而可以部署到不同的服务器服务器上。 分区和分表在分区之前要先分表，分表只是单台数据库的优化策略。为了让数据库的可扩展，便需要考虑分区，将表迁移到其它的数据库服务器上。 分片策略分片字段的选择：一般选择数据表的主键，但得保证不能使用auto_increment自增类型，可以自己实现一个id生成器（使用redis可实现）。 哈希算法可以采用取模的方式，数据分布均匀，扩容要成倍扩容，2台服务器扩展到4台服务器。 范围会造成访问不均的情况。 时间适合归档性质的数据。 映射关系映射表维护比较麻烦。 分区反向代理 MyCAT 官网：http://www.mycat.io/ Spock Proxy 关系型数据库瓶颈 缓存 全文检索 方案1：xunsearch http://www.xunsearch.com/ 方案2：Elasticsearch Elasticsearch入门教程参考： http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html NOSQL]]></content>
  </entry>
  <entry>
    <title><![CDATA[网站性能优化]]></title>
    <url>%2F2018%2F03%2F25%2F%E7%BD%91%E7%AB%99%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前端优化减少http请求数 图片地图。客户单图片地图可以使用map标签来实现。如果正在导航或者其他超链接中使用多个图片，将他们转换为图片地图是加速页面的最简单的方式。 CSS Sprites。将多幅图片合并成单独的图片。使用CSS的background-position属性，可以将HTML元素放置到背景图片期望的位置上。 内联图片。使用data:URL模式可以在Web页面中包含图片但无需额外的HTTP请求。 合并脚本和样式表。理想情况下，一个页面应该使用不多于一个脚本和样式表。 使用CDN存储前端资源CDN用于发布静态内容，如图片、脚本、样式和Flash。 可使用http://17ce.com这个网站网站使用CDN后在各地的响应速度。 添加Expires头充分利用浏览器缓存多域名访问前端资源使用单独的静态资源域名。资源数据的压缩压缩代码大小、图片大小，开启服务器gzip压缩优化首屏展示速度 延迟加载、异步加载 扩展阅读： 雅虎34条军规 Yslow Web性能测试插件 php优化使用opcode缓存opcode缓存简介 当解释器完成对脚本代码的分析后，便将它们生成可以直接运行的中间代码，也称为操作码（Operate Code，opcode）。Opcode cache的目地是避免重复编译，减少CPU和内存开销。如果动态内容的性能瓶颈不在于CPU和内存，而在于I/O操作，比如数据库查询带来的磁盘I/O开销，那么opcode cache的性能提升是非常有限的。 使用opcode缓存 从图中可以看出，使用了opcode缓存后，php代码的生命周期少了词典扫描和表达式（将PHP代码转换为语言片段[Tokens]）、解析文件（将Tokens转换成简单而有意义的表达式）、创建要执行的计算机代码（称为Opcode）几步。 opecode缓存-Zend OPcache安装使用PHP&gt;=5.5.0，php内置了OPcache,PHP小于5.5.0的话，要通过PCEL安装。 OPcache配置 123456789101112#检查脚本时间戳是否有更新的周期，以秒为单位。 设置为0会导致针对每个请求，OPcache都会检查脚本更新。opcache.revalidate_freq=60#如果启用，那么 OPcache 会每隔 opcache.revalidate_freq 设定的秒数 检查脚本是否更新。 如果禁用此选项，你必须使用 opcache_reset() 或者 opcache_invalidate() 函数来手动重置 OPcache，也可以 通过重启 Web 服务器来使文件系统更改生效opcache.validate_timestamps=1 #OPcache 哈希表中可存储的脚本文件数量上限。 真实的取值是在质数集合 &#123; 223, 463, 983, 1979, 3907, 7963, 16229, 32531, 65407, 130987 &#125; 中找到的第一个大于等于设置值的质数。 设置值取值范围最小值是 200，最大值在 PHP 5.5.6 之前是 100000，PHP 5.5.6 及之后是 1000000opcache.max_accelerated_files=1000#OPcache 的共享内存大小，以兆字节为单位。opcache.memory_consumption=512# 用来存储预留字符串的内存大小，以兆字节为单位。 PHP 5.3.0 之前的版本会忽略此配置指令。opcache.interned_strings_buffer=16#如果启用，则会使用快速停止续发事件。 所谓快速停止续发事件是指依赖 Zend 引擎的内存管理模块 一次释放全部请求变量的内存，而不是依次释放每一个已分配的内存块。opcache.fast_shutdown=1 PHP 7PHP 7相对比PHP 5.*,性能有了质的飞跃。PHP7相对于php5.6有2~3倍的性能提升。目前PHP的最新版本是PHP 7.2.5，相对于PHP 7.1也有部分性能提升。 性能评测文章参考： PHP的性能演进(从PHP5.0到PHP7.1的性能全评测PHP7.2、PHP7.1 性能对比 SWOOLE… php性能分析 xhui + tideways实践 tiways是一个测试php性能的php扩展，php版本要求是大于等于7.0。如果php版本小于7.0，可以使用xhprof扩展。xhgui用来展示测试数据，xhgui将数据保存到MongoDB。 安装tideways在ubuntu环境下： 1234echo &apos;deb http://s3-eu-west-1.amazonaws.com/qafoo-profiler/packages debian main&apos; &gt; /etc/apt/sources.list.d/tideways.listwget -qO - https://s3-eu-west-1.amazonaws.com/qafoo-profiler/packages/EEB5E8F4.gpg | sudo apt-key add -sudo apt-get updatesudo apt-get install tideways-php tideways-daemon 重启php-fpm，查看是否安装成功： 1sudo service php7.1-fpm restart 安装MongoDB123sudo apt-get install mongodbsudo apt-get install php-mongodbsudo /etc/init.d/mongodb start 安装xhgui123git clone https://github.com/laynefyc/xhgui-branch.gitcd xhgui-branchcomposer install 配置xhgui添加config/config.php,添加支持扩展为tideways 123return [ &apos;extension&apos; =&gt; &apos;tideways&apos;,]; MongoDB加索引1234567$ mongo &gt; use xhprof &gt; db.results.ensureIndex( &#123; &apos;meta.SERVER.REQUEST_TIME&apos; : -1 &#125; ) &gt; db.results.ensureIndex( &#123; &apos;profile.main().wt&apos; : -1 &#125; ) &gt; db.results.ensureIndex( &#123; &apos;profile.main().mu&apos; : -1 &#125; ) &gt; db.results.ensureIndex( &#123; &apos;profile.main().cpu&apos; : -1 &#125; ) &gt; db.results.ensureIndex( &#123; &apos;meta.url&apos; : 1 &#125; ) 配置nginx 1.要监控的应用 123456789101112131415161718 location ~ \.php$ &#123; fastcgi_split_path_info ^(.+\.php)(/.+)$; fastcgi_pass unix:/var/run/php/php7.1-fpm.sock; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; #加上下面的这两句 fastcgi_param TIDEWAYS_SAMPLERATE &quot;25&quot;; fastcgi_param PHP_VALUE &quot;auto_prepend_file=/home/vagrant/Code/xhgui/external/header.php&quot;; fastcgi_intercept_errors off; fastcgi_buffer_size 16k; fastcgi_buffers 4 16k; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300;&#125; 2.分析平台应用 12345678910#表示省略了一些nginx配置server &#123; listen 80; listen 443 ssl http2; server_name xhgui.app; root &quot;/home/vagrant/Code/xhgui/webroot&quot;; . . .&#125; 性能分析平台搭建效果 相关链接 ： https://github.com/tideways/php-xhprof-extension https://tideways.io/profiler/docs/setup/installation https://github.com/laynefyc/xhgui-branch.git 使用XHProf查找PHP性能瓶颈 Mysql优化表的设计优化 添加主键索引 innodb需要有一个主键，主键不要有业务用途。 表的字段类型选择 能选短整形，就不要选长整型 能选char就避免varchar 使用varchar类型的时候，长度够用就行 大字段考虑分开存储 字段适当冗余 索引的优化 索引不要建太多 在修改数据时，每个索引都要进行更新，降低写速度。 explain分析sql语句的执行计划 示例： 123456&gt; explain select * from typecho_contents where cid=40;+----+-------------+------------------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+------------------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| 1 | SIMPLE | typecho_contents | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | NULL |+----+-------------+------------------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ 重要列： type - 连接使用的类型 链接类型从最佳到最坏：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 解释： system:表仅有一行(=系统表)。这是const联接类型的一个特例。 const:表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const表很快,因为它们只读取一次! eq_ref:对于每个来自于前面的表的行组合,从该表中读取一行。这可能是最好的联接类型,除了const类型。 ref:对于每个来自于前面的表的行组合,所有有匹配索引值的行将从这张表中读取。 ref_or_null:该联接类型如同ref,但是添加了MySQL可以专门搜索包含NULL值的行。 index_merge:该联接类型表示使用了索引合并优化方法。 unique_subquery:该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。 index_subquery:该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr) range:只检索给定范围的行,使用一个索引来选择行。 index:该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。 一般来说，得保证查询至少达到range级别，最好能达到ref，否则就可能会出现性能问题。 key: Mysql实际使用的索引 Extra: Using filesort: Mysql需要额外的步骤排序，表示语句需要优化 Using temporary： 使用到临时表来存储查询结果，表示语句需要优化 SQL查询优化通过慢查询日志获取存在性能问题的SQL慢查询日志分析工具相关配置参数 12345678slow_query_log # 启动停止记录慢查日志，慢查询日志默认是没有开启的可以在配置文件中开启(on)slow_query_log_file # 指定慢查日志的存储路径及文件，日志存储和数据存储应该分开存储long_query_time # 指定记录慢查询日志SQL执行时间的阀值默认值为10秒通常,对于一个繁忙的系统来说,改为0.001秒(1毫秒)比较合适log_queries_not_using_indexes # 是否记录未使用索引的SQL 工具：pt-query-digest 1pt-query-digest --explain h=127.0.0.1,u=root,p=123456 slow-mysql.log pt-query-digest是用于分析mysql慢查询的一个工具，它可以分析binlog、General log、slowlog。可以把分析结果输出到文件中，也可以对SHOW PROCESSLIST或者通过tcpdump抓取的MySQL协议数据进行分析。分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间、次数、占比等，可以借助分析结果找出问题。 pt-query-digest工具的安装 因为pt-query-digest是包含在percona-tookit工具集中的，所以只要安装percona-tookit即可。percona-tookie链接：https://www.percona.com/doc/percona-toolkit/3.0/installation.html pt-query-digest工具的使用参考 https://www.cnblogs.com/luyucheng/p/6265873.html 实时获取存在性能问题的SQL直接通过表查询1234SELECT id,user,host,DB,command,time,state,infoFROM information_schema.processlistWHERE TIME&gt;=1 查询当前服务器执行超过1s的SQL，可以通过脚本周期性的来执行这条SQL，就能查出有问题的SQL。 通过pt-query-digst来分析1pt-query-digest --processlist h=host1 特定SQL的查询优化大表的数据修改大彪删除/更新100万或者更多1000万行记录，一次只删除/更新5000行记录，中间暂停几秒。 大表的结构在线修改添加一个新表（修改后的结构），老表数据导入新表，老表建立触发器，修改数据同步到新表， 老表加一个排它锁（重命名）， 新表重命名， 删除老表。 可以借助pt-online-schema-change工具来完成。 pt-oneline-schema-change 工具使用参考： https://blog.csdn.net/lovelichao12/article/details/73549939 优化not in和&lt;&gt;查询子查询改写为关联查询 12345select id,name from a where id not in (select id from b) 改写后： 12345select id,name from a left join b on a.id=b.idwhere b.id is null Mysql参考书籍： 《高性能mysql》 《MySQL 技术内幕：InnoDB 存储引擎》 《数据库索引设计与优化》 Nginx优化… 待完善…]]></content>
      <tags>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql数据库学习总结]]></title>
    <url>%2F2018%2F03%2F20%2FMysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[关系型数据库关系型数据库的三范式第一范式（1NF）: 每一列都是不可分割的原子数据项(基本类型列) 第二范式（2NF）： 要求实体的属性完全依赖于主关键字(无重复行) 第三范式（3NF）: 数据表不包含其它表已有的非主属性(无数据冗余) 关于数据库的规范设计，都会谈到是否符合三范式。但是考虑到数据库的性能优化，也不必都按照三范式来设计，可以做数据的适当冗余。如为了查询效率，在商品表，可以设置个img_url字段放图片的主图。 MySQL本质了解mysql逻辑架构 1.最上层是一些客户端和连接服务，包含本地sock通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 2.第二层架构主要完成大多的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化及部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如过程、函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等，最后生成相应的执行操作。如果是select语句，服务器还会查询内部的缓存。如果缓存空间足够大，这样在解决大量读操作的环境中能够很好的提升系统的性能。 3.存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。 4.数据存储层，主要是将数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互。 MySQL核心模块 • Server Initialization Module 命令行、配置文件解析、内存分配 • Connection Manager 协议监听和协议转发 • Thread Manager 新建线程处理请求 • Connection Thread 新建新的,或者从线程缓存中去取 • User Authentication Module 验证用户身份 • Access Control Module 访问控制 • Parser 接收请求,解析进入命令分发或者进入查询 • Command Dispatcher 解析器分发给命令分发器 • Query Cache Module 查询缓存检查(SELECT、DELETE、UPDATE) • Optimizer 查询优化器 • Table Manager 打开表,获取锁 • Table Modification Modules 表更新 • Table Maintenance Module 表维护 • Status Reporting Module 状态报告 • Abstracted Storage Engine Interface (Table Handler) 抽象引擎接口 • Storage Engine Implementations (MyISAM, InnoDB...) 存储引擎实现 • Logging Module 日志记录 • Replication Master Module 复制主模块 • Replication Slave Module 复制从模块 • Client/Server Protocol API 客户端、服务器协议 API • Low-Level Network I/O API 底层网络 I/O API • Core API 核心 API 存储引擎的区别和选择存储引擎是mysql提供的文件访问层的一个抽象接口来定制一种文件访问机制。 mysql的存储引擎包括:MyISAM、InnoDB、BDB、MEMORY、MERGE、EXAMPLE、NDBCluster、ARCHIVE、CSV、BLACKHOLE、FEDERATED等。 MyISAM:不支持事务,支持全文索引,表级锁；数据文件全量备份，可以直接拷贝数据文件进行备份；适合处理读频率远大于写频率的静态表。 InnoDB:支持事务,5.6以后支持全文索引,默认行级锁；数据文件两种形式(单一文件形式和多文件形式,以共享表空间与独占表空间存储)；适用于高并发读写。 MySQL InnoDB的存储文件参考：http://blog.csdn.net/chenjiayi_yun/article/details/45533909 MySQL插件NoSql 插件 HandlerSocket 中文全文索引插件 mysqlcft （mysql5.7内置有n-gram parser插件） InnoDB引擎中的Memcached插件 MySQL中的事务事务的ACID:• 原子性(Atomicity ) 全部执行或全部不执行 • 一致性( Consistency ) 事务前后数据都是一致性状态,约束等 • 隔离性或独立性( Isolation) 事务之间是独立的,和级别相关 • 持久性(Durabilily) 事务完成即持久化存储 MysSQL锁表类型1- 表级锁(MyISAM) 开销小,加锁快;不会出现死锁;锁定粒 度大,发生锁冲突的概率最高,并发度最低 可以通过检查table_locks_waited和table_locks_immediate状态变量来分析系统上的表锁定争夺： mysql> show status like 'table%'; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | Table_locks_immediate | 2979 | | Table_locks_waited | 0 | +-----------------------+-------+ 2 rows in set (0.00 sec)) 如果Table_locks_waited的值比较高，则说明存在着较严重的表级锁争用情况。 MySQL的表级锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。锁模式的兼容性如表20-1所示。 MySQL中的表锁兼容性 请求锁模式 是否兼容 当前锁模式 None 读锁 写锁 读锁 是 是 否 写锁 是 否 否 行级锁(InnoDB) 开销大,加锁慢;会出现死锁;锁定粒度最 小,发生锁冲突的概率最低,并发度也最高 可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况： mysql> show status like 'innodb_row_lock%'; +-------------------------------+-------+ | Variable_name | Value | +-------------------------------+-------+ | InnoDB_row_lock_current_waits | 0 | | InnoDB_row_lock_time | 0 | | InnoDB_row_lock_time_avg | 0 | | InnoDB_row_lock_time_max | 0 | | InnoDB_row_lock_waits | 0 | +-------------------------------+-------+ 5 rows in set (0.01 sec) 如果发现锁争用比较严重，如InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高，还可以通过设置InnoDB Monitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。 页面锁 开销和加锁时间界于表锁和行锁之间;会出现死锁;锁定 粒度界于表锁和行锁之间,并发度一般 使用悲观锁和乐观锁解决并发悲观锁在关系数据库管理系统里，悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 在DBMS中，悲观锁正是利用数据库本身提供的锁机制来实现的。 乐观锁乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。 参考： mysql悲观锁总结和实践 mysql乐观锁总结和实践 深入理解乐观锁与悲观锁 海量数据的分页优化方案 建立合适的索引 使用Redis缓存count,根据访问热度缓存靠后的分页数据 查找出limit的开始行id，然后用where拼接，如：where id&gt;*** limit 0,99 产品设计优化 MySQL的安装与配置MySQL源码安装下面在CentOS环境下安装、参考Oneinstack 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137# 下载mysql源码包wget -4 --tries=6 -c --no-check-certificate https://mirrors.tuna.tsinghua.edu.cn/mysql/downloads/MySQL-5.7/mysql-5.7.21.tar.gz# 进入软件目录pushd /opt/software/src# 添加mysql用户useradd -M -s /sbin/nologin mysql# 创建mysql的安装目录mkdir -p /usr/local/mysql# 创建mysql data目录mkdir -p /data/mysql# 更改mysql data目录权限chown mysql.mysql -R /data/mysqltar xzf mysql-5.7.21.tar.gzpushd mysql-5.7.21cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/data/mysql \ -DSYSCONFDIR=/etc \ -DWITH_INNOBASE_STORAGE_ENGINE=1 \ -DWITH_PARTITION_STORAGE_ENGINE=1 \ -DWITH_FEDERATED_STORAGE_ENGINE=1 \ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \ -DWITH_MYISAM_STORAGE_ENGINE=1 \ -DWITH_EMBEDDED_SERVER=1 \ -DENABLE_DTRACE=0 \ -DENABLED_LOCAL_INFILE=1 \ -DDEFAULT_CHARSET=utf8mb4 \ -DDEFAULT_COLLATION=utf8mb4_general_ci \ -DEXTRA_CHARSETS=all \ -DCMAKE_EXE_LINKER_FLAGS=&apos;-ljemalloc&apos;makemake installpopdrm -rf mysql-5.7.21cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqldsed -i &quot;s@^basedir=.*@basedir=/usr/local/mysql@&quot; /etc/init.d/mysqldsed -i &quot;s@^datadir=.*@datadir=/data/mysql@&quot; /etc/init.d/mysqldchmod +x /etc/init.d/mysqldchkconfig --add mysqldchkconfig mysqld on# 添加mysql配置 cat &gt; /etc/my.cnf &lt;&lt; EOF[client]port = 3306socket = /tmp/mysql.sockdefault-character-set = utf8mb4[mysql]prompt=&quot;MySQL [\\d]&gt; &quot;no-auto-rehash[mysqld]port = 3306socket = /tmp/mysql.sockbasedir = /usr/local/mysqldatadir = /data/mysqlpid-file = /data/mysql/mysql.piduser = mysqlbind-address = 0.0.0.0server-id = 1init-connect = &apos;SET NAMES utf8mb4&apos;character-set-server = utf8mb4skip-name-resolve#skip-networkingback_log = 300max_connections = 1000max_connect_errors = 6000open_files_limit = 65535table_open_cache = 128max_allowed_packet = 500Mbinlog_cache_size = 1Mmax_heap_table_size = 8Mtmp_table_size = 16Mread_buffer_size = 2Mread_rnd_buffer_size = 8Msort_buffer_size = 8Mjoin_buffer_size = 8Mkey_buffer_size = 4Mthread_cache_size = 8query_cache_type = 1query_cache_size = 8Mquery_cache_limit = 2Mft_min_word_len = 4log_bin = mysql-binbinlog_format = mixedexpire_logs_days = 7log_error = /dta/mysql/mysql-error.logslow_query_log = 1long_query_time = 1slow_query_log_file = /data/mysql/mysql-slow.logperformance_schema = 0explicit_defaults_for_timestamp#lower_case_table_names = 1skip-external-lockingdefault_storage_engine = InnoDB#default-storage-engine = MyISAMinnodb_file_per_table = 1innodb_open_files = 500innodb_buffer_pool_size = 64Minnodb_write_io_threads = 4innodb_read_io_threads = 4innodb_thread_concurrency = 0innodb_purge_threads = 1innodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 2Minnodb_log_file_size = 32Minnodb_log_files_in_group = 3innodb_max_dirty_pages_pct = 90innodb_lock_wait_timeout = 120bulk_insert_buffer_size = 8Mmyisam_sort_buffer_size = 8Mmyisam_max_sort_file_size = 10Gmyisam_repair_threads = 1interactive_timeout = 28800wait_timeout = 28800[mysqldump]quickmax_allowed_packet = 500M[myisamchk]key_buffer_size = 8Msort_buffer_size = 8Mread_buffer = 4Mwrite_buffer = 4MEOF# 数据库初始化/usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysqlchown mysql.mysql -R /data/mysqlservice mysqld start# 设置环境变量echo &quot;export PATH=/usr/local/mysql/bin:\$PATH&quot; &gt;&gt; /etc/profile[ -z &quot;$(grep ^&apos;export PATH=&apos; /etc/profile)&quot; ] &amp;&amp; echo &quot;export PATH=/usr/local/mysql/bin:\$PATH&quot; &gt;&gt; /etc/profile[ -n &quot;$(grep ^&apos;export PATH=&apos; /etc/profile)&quot; -a -z &quot;$(grep /usr/local/mysql /etc/profile)&quot; ] &amp;&amp; sed -i &quot;s@^export PATH=\(.*\)@export PATH=/usr/local/mysql/bin:\1@&quot; /etc/profile# 设置密码/usr/local/mysql/bin/mysql -e &quot;grant all privileges on *.* to root@&apos;127.0.0.1&apos; identified by &quot;123456&quot; with grant option;&quot;/usr/local/mysql/bin/mysql -e &quot;grant all privileges on *.* to root@&apos;localhost&apos; identified by &quot;123456&quot; with grant option;&quot;# 添加动态链接库echo &quot;/usr/local/mysql/lib&quot; &gt; /etc/ld.so.conf.d/mysql.confldconfigservice mysqld restart MySQL源码目录 • BUILD 编译脚本 • client 命令行工具代码(mysql,mysqladmin) • cmd-line-utils 增强命令行的第三方库 (libedit 如 readline). • dbug 调试库 • libevent 由于 5.6 支持 某个插件的库 • plugin 插件所在的库 • libmysql MySQL 的库,其他客户端,经如C/PHP 访问MySQL需 要引用这个目录的库 • mysys 核心可移植性或者工具API • regex 正则表达式库 • scripts 脚本库,如 mysqld_safe 所在 • sql MySQL 的核心所在,用C++所写 • sql-common 客户端、服务器能用代码 • strings 字符串库 • storage 存储引擎所在的库 • vio 底层网络I/O操作库 • zlib库 数据库配置优化基础配置连接数配置通过show variables like &#39;%conn%&#39;;查看配置 max_connections 设置整个服务器最大session连接数 max_user_connections 每个用户的session连接个数,值为0时表示每个用户的连接数不受限制 网络配置skip-name-resolve：禁止掉DNS的查询 解释：mysql会在用户登录过程中对客户端IP进行DNS反查，不管你是使用IP登录还是域名登录，这个反查的过程都是在的。所以如果你的mysql所在的服务器的DNS有问题或者质量不好，那么就有可能造成127.0.0.1登录很快，用域名或者IP登录数据库很慢的DNS解析问题。 数据库加这个参数速度会变快skip-name-resolve，但是也有注意点，mysql.user 表里面的host不要用localhost之类的，要用127.0.0.1，不然连自己都连不上数据库，会报错。 缓存配置查询缓存查询缓存的作用就是当查询接收到一个和之前同样的查询，服务器将会从查询缓存种检索结果，而不是再次分析和执行上次的查询。这样就大大提高了性能，节省时间。当查询很大、更新很少的情况下可以使用查询缓存。 查看缓存设置1show variables like &apos;%query_cache%&apos;; 输出如下： +------------------------------+---------+ | Variable_name | Value | +------------------------------+---------+ | have_query_cache | YES | | query_cache_limit | 1048576 | | query_cache_min_res_unit | 4096 | | query_cache_size | 1048576 | | query_cache_type | OFF | | query_cache_wlock_invalidate | OFF | +------------------------------+---------+ 查看缓存的状态使用show status like &#39;%Qcache%&#39;; 输出结果： +-------------------------+---------+ | Variable_name | Value | +-------------------------+---------+ | Qcache_free_blocks | 1 | | Qcache_free_memory | 1031832 | | Qcache_hits | 0 | | Qcache_inserts | 0 | | Qcache_lowmem_prunes | 0 | | Qcache_not_cached | 4 | | Qcache_queries_in_cache | 0 | | Qcache_total_blocks | 1 | +-------------------------+---------+ 参考：mysql查询缓存打开、设置、参数查询、性能变量意思 日志配置通用查询日志通用查询日志：记录建立的客户端连接和执行的语句 1). 查看通用查询日志配置1show variables like &apos;%general%&apos;; 输出结果： +------------------+------------------------------+ | Variable_name | Value | +------------------+------------------------------+ | general_log | OFF | | general_log_file | /data/mysql/xxxxxx.log | +------------------+------------------------------+ 通用查询日志默认是关闭的。 2). 查看当前日志输出的格式 1MySQL [(none)]&gt; show variables like &apos;%log_output%&apos;; 输出结果： +---------------+-------+ | Variable_name | Value | +---------------+-------+ | log_output | FILE | +---------------+-------+ 1 row in set (0.01 sec) 日志格式可以是FILE（存储在数数据库的数据文件中的hostname.log），也可以是TABLE（存储在数据库中的mysql.general_log） 3) 开启通用查询日志的方式 通过set命令设置，只对当前mysql生效，重启失效 12set global general_log=on;set global log_output=&apos;TABLE&apos;; # 值为“FILE”、“TABLE“或者“FILE,TABLE” 通过配置文件my.cnf配置 12general_log=1 # 为1表示开启通用日志查询，值为0表示关闭通用日志查询log_output=FILE,TABLE # 设置通用日志的输出格式为文件和表 慢查询日志MySQL的慢查询日志是MySQL提供的一种日志记录，用来记录在MySQL中响应时间超过阈值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中（日志可以写入文件或者数据库表，如果对性能要求高的话，建议写文件）。默认情况下，MySQL数据库是不开启慢查询日志的，long_query_time的默认值为10（即10秒，通常设置为1秒），即运行10秒以上的语句是慢查询语句。 1) 查看是否开启慢查询日志 1show variables like &apos;%quer%&apos;; 输出结果中 slow_query_log值为ON时表示开启 slow_query_log_file 的值是记录的慢查询日志到文件中（注意：默认名为主机名.log，慢查询日志是否写入指定文件中，需要指定慢查询的输出日志格式为文件，相关命令为：show variables like ‘%log_output%’；去查看输出的格式。当设置为TABLE时，慢查询日志输出至mysql.slow_log中） 2) 在配置文件中配置慢查询 123slow_query_log = 1long_query_time = 1slow_query_log_file = /data/mysql/mysql-slow.log 3) 如何制造慢查询，看慢查询设置是否有效 1&gt; select sleep(5) 二进制配置主要作数据库的恢复和同步使用 123log_bin = mysql-binbinlog_format = mixedexpire_logs_days = 7 错误日志1log_error = /data/mysql/mysql-error.log]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让github上fork的项目同步原项目]]></title>
    <url>%2F2018%2F02%2F24%2F%E8%AE%A9github%E4%B8%8Afork%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%90%8C%E6%AD%A5%E5%8E%9F%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[1234567891011121314## 先clone到本地仓库git clone https://github.com/yunshu2009/think.git## 保持和远程仓库同步git remote add upstream https://github.com/top-think/think.git## 拉取远程仓库最新代码git fetch upstream## 合并到本地仓库git merge upstream/master## 及时更新最新改动git pull --rebase]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SSR科学上网]]></title>
    <url>%2F2018%2F02%2F19%2F%E4%BD%BF%E7%94%A8SSR%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[使用一键安装脚本安装shadowsocksR参考：https://shadowsocks.be/9.html 123wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.shchmod +x shadowsocksR.sh./shadowsocksR.sh 在CentOS 7上安装BBR加速参考： 部署方法：https://www.vultr.com/docs/how-to-deploy-google-bbr-on-centos-7) 一键安装脚本：https://github.com/teddysun/across/raw/master/bbr.sh 检测linux vps是xen openvz还是kvm的方法https://blog.slogra.com/post-632.html SSR客户端MAC客户端： https://github.com/qinyuhang/ShadowsocksX-NG-R/releases Linux客户端：https://raw.githubusercontent.com/the0demiurge/CharlesScripts/master/charles/bin/ssr Windows客户端：https://github.com/shadowsocksr-backup/shadowsocksr-csharp/releases IOS客户端：Potatso Lite、Potatso、shadowrocket (需要使用美区apple id下载软件) SSR多用户配置配置文件如下 123456789101112131415161718192021&#123;&quot;server&quot;:&quot;0.0.0.0&quot;,&quot;server_ipv6&quot;: &quot;[::]&quot;,&quot;local_address&quot;:&quot;127.0.0.1&quot;,&quot;local_port&quot;:1080,&quot;port_password&quot;:&#123; &quot;8989&quot;:&quot;password1&quot;,//着里输入想要的端口和密码 &quot;8990&quot;:&quot;password2&quot;， &quot;8991&quot;:&quot;password3&quot;&#125;,&quot;timeout&quot;:300,&quot;method&quot;:&quot;aes-256-cfb&quot;,//加密方式可以修改也可以不修改本人用chacha20&quot;protocol&quot;: &quot;origin&quot;,//协议也是可以修改了本人用auth_sha1&quot;protocol_param&quot;: &quot;&quot;,&quot;obfs&quot;: &quot;plain&quot;,//这里很重要,免流的请注意必须修改,本人用http_simple&quot;obfs_param&quot;: &quot;&quot;,&quot;redirect&quot;: &quot;&quot;,&quot;dns_ipv6&quot;: false,&quot;fast_open&quot;: false,&quot;workers&quot;: 1&#125; 然后修改防火墙，添加上面添加的端口即可，重启防火墙和SSR即可。 参考链接：https://www.cnblogs.com/gne-hwz/p/6662000.html 其他参考 http://blog.sina.com.cn/s/blog_4891cbc50102x5lw.html SSR共享如果你感觉梯子搭建麻烦，也可联系我共享SSR ~~]]></content>
      <tags>
        <tag>科学上网</tag>
      </tags>
  </entry>
</search>
